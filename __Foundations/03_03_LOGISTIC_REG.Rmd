## Logistic Regression: Key Concepts for Data Science Interviews

**1. Basic Definition:**
   - Logistic Regression is a statistical method used for **binary classification** tasks. It predicts the probability that a given input belongs to a certain class, typically between two classes (e.g., 0 or 1).

**2. Sigmoid Function:**
   - The core of logistic regression is the **sigmoid function**, which maps the input to a probability between 0 and 1. The sigmoid function is defined as:
     \[
     \sigma(z) = \frac{1}{1 + e^{-z}}
     \]
   - Here, \( z = \mathbf{w}^T \mathbf{x} + b \) is the linear combination of input features \( \mathbf{x} \), weights \( \mathbf{w} \), and bias \( b \).

**3. Interpretation of Coefficients:**
   - The coefficients \( \mathbf{w} \) represent the impact of each feature on the probability of the output. A positive coefficient increases the likelihood of the outcome being 1, while a negative coefficient decreases it.
   - The odds ratio \( e^{w_i} \) can be used to interpret the impact of a one-unit increase in the feature \( x_i \).

**4. Loss Function:**
   - Logistic regression uses the **log loss** (or binary cross-entropy loss) to measure the difference between predicted probabilities and actual labels. The log loss is defined as:
     \[
     L(y, \hat{y}) = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]
     \]
   - The goal is to minimize this loss during training.

**5. Decision Boundary:**
   - The decision boundary is the threshold at which the predicted probability is converted into a class label. By default, this threshold is 0.5, meaning if \( \hat{y} \geq 0.5 \), the model predicts class 1, otherwise class 0.

**6. Regularization:**
   - To prevent overfitting, logistic regression can include regularization terms:
     - **L1 Regularization (Lasso):** Adds a penalty proportional to the absolute value of the coefficients, leading to sparse solutions (some coefficients may be zero).
     - **L2 Regularization (Ridge):** Adds a penalty proportional to the square of the coefficients, which shrinks the coefficients towards zero but does not set them to zero.
     - **Elastic Net:** Combines L1 and L2 regularization.

**7. Assumptions:**
   - **Linearity:** The log-odds (the logarithm of the odds) of the outcome is a linear combination of the input features.
   - **Independence:** The observations should be independent of each other.
   - **No Multicollinearity:** The input features should not be highly correlated with each other.

**8. Metrics for Evaluation:**
   - **Accuracy:** The proportion of correctly classified instances.
   - **Precision and Recall:** Useful when dealing with imbalanced datasets.
   - **F1 Score:** The harmonic mean of precision and recall, providing a single metric for model performance.
   - **ROC-AUC:** Measures the trade-off between true positive rate and false positive rate across different thresholds.

**9. Use Cases:**
   - **Binary Classification:** Spam detection, medical diagnosis (e.g., disease vs. no disease), credit scoring (e.g., default vs. no default).
   - **Customer Segmentation:** Classifying customers based on purchase likelihood.
   - **Predicting Outcomes:** Logistic regression is often used when the outcome variable is binary.

### What You Need to Know:
- Understand the **sigmoid function** and how it transforms linear outputs into probabilities.
- Know how to interpret the **coefficients** in logistic regression and what they imply about the relationship between features and the outcome.
- Be familiar with the **log loss function** and how logistic regression optimizes it.
- Understand the concept of a **decision boundary** and how it's used to classify instances.
- Learn about **regularization techniques** and why they are important for controlling overfitting.
- Be aware of the **assumptions** underlying logistic regression and how violations might affect the model.
- Be prepared to discuss **evaluation metrics** and when to use each one.

Would you like to explore any of these topics further or need practice questions on logistic regression?
