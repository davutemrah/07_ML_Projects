<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 ML Modeling | Machine Learning</title>
  <meta name="description" content="This is a collection of notes to my self" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 ML Modeling | Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a collection of notes to my self" />
  <meta name="github-repo" content="davutemrah/davutemrah.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 ML Modeling | Machine Learning" />
  
  <meta name="twitter:description" content="This is a collection of notes to my self" />
  

<meta name="author" content="Davut Ayan" />


<meta name="date" content="2024-09-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="extract-transform-loading.html"/>
<link rel="next" href="model-evaluation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="projects.html"><a href="projects.html"><i class="fa fa-check"></i><b>1</b> Projects</a></li>
<li class="chapter" data-level="2" data-path="machine-learning-fundamentals.html"><a href="machine-learning-fundamentals.html"><i class="fa fa-check"></i><b>2</b> Machine Learning Fundamentals</a>
<ul>
<li class="chapter" data-level="2.1" data-path="machine-learning-fundamentals.html"><a href="machine-learning-fundamentals.html#definitions"><i class="fa fa-check"></i><b>2.1</b> definitions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="machine-learning-fundamentals.html"><a href="machine-learning-fundamentals.html#data-science"><i class="fa fa-check"></i><b>2.1.1</b> Data Science</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html"><i class="fa fa-check"></i><b>3</b> Machine Learning Fundementals</a>
<ul>
<li class="chapter" data-level="3.1" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#overfitting"><i class="fa fa-check"></i><b>3.1</b> Overfitting</a></li>
<li class="chapter" data-level="3.2" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#underfitting"><i class="fa fa-check"></i><b>3.2</b> Underfitting</a></li>
<li class="chapter" data-level="3.3" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>3.3</b> Bias-Variance Trade-off</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#bias"><i class="fa fa-check"></i><b>3.3.1</b> Bias</a></li>
<li class="chapter" data-level="3.3.2" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#variance"><i class="fa fa-check"></i><b>3.3.2</b> Variance</a></li>
<li class="chapter" data-level="3.3.3" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#bias-vs.-variance-trade-off"><i class="fa fa-check"></i><b>3.3.3</b> Bias vs. Variance Trade-Off:</a></li>
<li class="chapter" data-level="3.3.4" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#bias-vs.-variance-trade-off-1"><i class="fa fa-check"></i><b>3.3.4</b> Bias vs. Variance Trade-Off:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>4</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="machine-learning.html"><a href="machine-learning.html#ml-algorithms-intro"><i class="fa fa-check"></i><b>4.1</b> ML Algorithms Intro</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="machine-learning.html"><a href="machine-learning.html#binary-classification"><i class="fa fa-check"></i><b>4.1.1</b> Binary Classification:</a></li>
<li class="chapter" data-level="4.1.2" data-path="machine-learning.html"><a href="machine-learning.html#multi-class-classification"><i class="fa fa-check"></i><b>4.1.2</b> Multi-Class Classification:</a></li>
<li class="chapter" data-level="4.1.3" data-path="machine-learning.html"><a href="machine-learning.html#continuous-outcome-regression"><i class="fa fa-check"></i><b>4.1.3</b> Continuous Outcome (Regression):</a></li>
<li class="chapter" data-level="4.1.4" data-path="machine-learning.html"><a href="machine-learning.html#random-forest-vs-decision-trees"><i class="fa fa-check"></i><b>4.1.4</b> Random Forest vs Decision Trees</a></li>
<li class="chapter" data-level="4.1.5" data-path="machine-learning.html"><a href="machine-learning.html#random-forest-vs-gradient-boosting"><i class="fa fa-check"></i><b>4.1.5</b> Random Forest vs Gradient Boosting</a></li>
<li class="chapter" data-level="4.1.6" data-path="machine-learning.html"><a href="machine-learning.html#overall-considerations"><i class="fa fa-check"></i><b>4.1.6</b> Overall Considerations:</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="machine-learning.html"><a href="machine-learning.html#ml-libraries-in-python"><i class="fa fa-check"></i><b>4.2</b> ML Libraries in Python</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="machine-learning.html"><a href="machine-learning.html#tensorflow"><i class="fa fa-check"></i><b>4.2.1</b> TensorFlow</a></li>
<li class="chapter" data-level="4.2.2" data-path="machine-learning.html"><a href="machine-learning.html#pytorch"><i class="fa fa-check"></i><b>4.2.2</b> PyTorch</a></li>
<li class="chapter" data-level="4.2.3" data-path="machine-learning.html"><a href="machine-learning.html#big-data-solutions"><i class="fa fa-check"></i><b>4.2.3</b> Big data solutions</a></li>
<li class="chapter" data-level="4.2.4" data-path="machine-learning.html"><a href="machine-learning.html#databricks"><i class="fa fa-check"></i><b>4.2.4</b> Databricks</a></li>
<li class="chapter" data-level="4.2.5" data-path="machine-learning.html"><a href="machine-learning.html#tensorflow-1"><i class="fa fa-check"></i><b>4.2.5</b> TensorFlow</a></li>
<li class="chapter" data-level="4.2.6" data-path="machine-learning.html"><a href="machine-learning.html#pytorch-1"><i class="fa fa-check"></i><b>4.2.6</b> PyTorch</a></li>
<li class="chapter" data-level="4.2.7" data-path="machine-learning.html"><a href="machine-learning.html#ensemble-learning-in-machine-learning"><i class="fa fa-check"></i><b>4.2.7</b> <strong>Ensemble Learning in Machine Learning</strong></a></li>
<li class="chapter" data-level="4.2.8" data-path="machine-learning.html"><a href="machine-learning.html#key-concepts-of-ensemble-learning"><i class="fa fa-check"></i><b>4.2.8</b> <strong>Key Concepts of Ensemble Learning:</strong></a></li>
<li class="chapter" data-level="4.2.9" data-path="machine-learning.html"><a href="machine-learning.html#bagging-bootstrap-aggregating"><i class="fa fa-check"></i><b>4.2.9</b> <strong>1. Bagging (Bootstrap Aggregating):</strong></a></li>
<li class="chapter" data-level="4.2.10" data-path="machine-learning.html"><a href="machine-learning.html#boosting"><i class="fa fa-check"></i><b>4.2.10</b> <strong>2. Boosting:</strong></a></li>
<li class="chapter" data-level="4.2.11" data-path="machine-learning.html"><a href="machine-learning.html#stacking-stacked-generalization"><i class="fa fa-check"></i><b>4.2.11</b> <strong>3. Stacking (Stacked Generalization):</strong></a></li>
<li class="chapter" data-level="4.2.12" data-path="machine-learning.html"><a href="machine-learning.html#other-ensemble-methods"><i class="fa fa-check"></i><b>4.2.12</b> <strong>Other Ensemble Methods:</strong></a></li>
<li class="chapter" data-level="4.2.13" data-path="machine-learning.html"><a href="machine-learning.html#advantages-of-ensemble-learning"><i class="fa fa-check"></i><b>4.2.13</b> <strong>Advantages of Ensemble Learning:</strong></a></li>
<li class="chapter" data-level="4.2.14" data-path="machine-learning.html"><a href="machine-learning.html#disadvantages-of-ensemble-learning"><i class="fa fa-check"></i><b>4.2.14</b> <strong>Disadvantages of Ensemble Learning:</strong></a></li>
<li class="chapter" data-level="4.2.15" data-path="machine-learning.html"><a href="machine-learning.html#summary"><i class="fa fa-check"></i><b>4.2.15</b> <strong>Summary:</strong></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="machine-learning.html"><a href="machine-learning.html#regularization"><i class="fa fa-check"></i><b>4.3</b> Regularization</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="machine-learning.html"><a href="machine-learning.html#lasso-regression"><i class="fa fa-check"></i><b>4.3.1</b> Lasso Regression</a></li>
<li class="chapter" data-level="4.3.2" data-path="machine-learning.html"><a href="machine-learning.html#bayesian-models"><i class="fa fa-check"></i><b>4.3.2</b> Bayesian Models</a></li>
<li class="chapter" data-level="4.3.3" data-path="machine-learning.html"><a href="machine-learning.html#correlation-between-lasso-and-bayesian-models"><i class="fa fa-check"></i><b>4.3.3</b> Correlation Between Lasso and Bayesian Models</a></li>
<li class="chapter" data-level="4.3.4" data-path="machine-learning.html"><a href="machine-learning.html#summary-1"><i class="fa fa-check"></i><b>4.3.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="machine-learning.html"><a href="machine-learning.html#logistic-regression-key-concepts-for-data-science-interviews"><i class="fa fa-check"></i><b>4.4</b> Logistic Regression: Key Concepts for Data Science Interviews</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="machine-learning.html"><a href="machine-learning.html#what-you-need-to-know"><i class="fa fa-check"></i><b>4.4.1</b> What You Need to Know:</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="machine-learning.html"><a href="machine-learning.html#gradient-boosting-trees-gbt"><i class="fa fa-check"></i><b>4.5</b> Gradient Boosting Trees (GBT)</a></li>
<li class="chapter" data-level="4.6" data-path="machine-learning.html"><a href="machine-learning.html#random-forest-2"><i class="fa fa-check"></i><b>4.6</b> Random Forest</a></li>
<li class="chapter" data-level="4.7" data-path="machine-learning.html"><a href="machine-learning.html#xgboost-key-concepts-for-data-science-interviews"><i class="fa fa-check"></i><b>4.7</b> XGBoost: Key Concepts for Data Science Interviews</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="machine-learning.html"><a href="machine-learning.html#what-you-need-to-know-1"><i class="fa fa-check"></i><b>4.7.1</b> What You Need to Know:</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="machine-learning.html"><a href="machine-learning.html#neural-networks-key-concepts-for-data-science-interviews"><i class="fa fa-check"></i><b>4.8</b> Neural Networks: Key Concepts for Data Science Interviews</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="machine-learning.html"><a href="machine-learning.html#basic-structure"><i class="fa fa-check"></i><b>4.8.1</b> Basic Structure:</a></li>
<li class="chapter" data-level="4.8.2" data-path="machine-learning.html"><a href="machine-learning.html#activation-functions"><i class="fa fa-check"></i><b>4.8.2</b> Activation Functions:</a></li>
<li class="chapter" data-level="4.8.3" data-path="machine-learning.html"><a href="machine-learning.html#forward-and-backpropagation"><i class="fa fa-check"></i><b>4.8.3</b> Forward and Backpropagation:</a></li>
<li class="chapter" data-level="4.8.4" data-path="machine-learning.html"><a href="machine-learning.html#loss-functions"><i class="fa fa-check"></i><b>4.8.4</b> Loss Functions:</a></li>
<li class="chapter" data-level="4.8.5" data-path="machine-learning.html"><a href="machine-learning.html#optimization-algorithms"><i class="fa fa-check"></i><b>4.8.5</b> Optimization Algorithms:</a></li>
<li class="chapter" data-level="4.8.6" data-path="machine-learning.html"><a href="machine-learning.html#regularization-techniques"><i class="fa fa-check"></i><b>4.8.6</b> Regularization Techniques:</a></li>
<li class="chapter" data-level="4.8.7" data-path="machine-learning.html"><a href="machine-learning.html#common-architectures"><i class="fa fa-check"></i><b>4.8.7</b> Common Architectures:</a></li>
<li class="chapter" data-level="4.8.8" data-path="machine-learning.html"><a href="machine-learning.html#overfitting-and-underfitting"><i class="fa fa-check"></i><b>4.8.8</b> Overfitting and Underfitting:</a></li>
<li class="chapter" data-level="4.8.9" data-path="machine-learning.html"><a href="machine-learning.html#what-you-need-to-know-2"><i class="fa fa-check"></i><b>4.8.9</b> What You Need to Know:</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="machine-learning.html"><a href="machine-learning.html#naive-bayes"><i class="fa fa-check"></i><b>4.9</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="machine-learning.html"><a href="machine-learning.html#bayesian-classification"><i class="fa fa-check"></i><b>4.9.1</b> Bayesian Classification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="extract-transform-loading.html"><a href="extract-transform-loading.html"><i class="fa fa-check"></i><b>5</b> Extract-Transform-Loading</a>
<ul>
<li class="chapter" data-level="5.1" data-path="extract-transform-loading.html"><a href="extract-transform-loading.html#outlier-detection"><i class="fa fa-check"></i><b>5.1</b> Outlier Detection</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ml-modeling.html"><a href="ml-modeling.html"><i class="fa fa-check"></i><b>6</b> ML Modeling</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ml-modeling.html"><a href="ml-modeling.html#objective"><i class="fa fa-check"></i><b>6.1</b> Objective</a></li>
<li class="chapter" data-level="6.2" data-path="ml-modeling.html"><a href="ml-modeling.html#data-processing"><i class="fa fa-check"></i><b>6.2</b> Data Processing</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ml-modeling.html"><a href="ml-modeling.html#data-collection"><i class="fa fa-check"></i><b>6.2.1</b> Data collection</a></li>
<li class="chapter" data-level="6.2.2" data-path="ml-modeling.html"><a href="ml-modeling.html#data-cleaning"><i class="fa fa-check"></i><b>6.2.2</b> Data Cleaning</a></li>
<li class="chapter" data-level="6.2.3" data-path="ml-modeling.html"><a href="ml-modeling.html#feature-engineering"><i class="fa fa-check"></i><b>6.2.3</b> Feature Engineering</a></li>
<li class="chapter" data-level="6.2.4" data-path="ml-modeling.html"><a href="ml-modeling.html#implementation-and-impact"><i class="fa fa-check"></i><b>6.2.4</b> Implementation and Impact</a></li>
<li class="chapter" data-level="6.2.5" data-path="ml-modeling.html"><a href="ml-modeling.html#lessons-learned-and-future-work"><i class="fa fa-check"></i><b>6.2.5</b> Lessons Learned and Future Work</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ml-modeling.html"><a href="ml-modeling.html#model-selection"><i class="fa fa-check"></i><b>6.3</b> Model Selection</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="ml-modeling.html"><a href="ml-modeling.html#understand-the-problem-type"><i class="fa fa-check"></i><b>6.3.1</b> Understand the Problem Type</a></li>
<li class="chapter" data-level="6.3.2" data-path="ml-modeling.html"><a href="ml-modeling.html#understand-the-data"><i class="fa fa-check"></i><b>6.3.2</b> Understand the Data</a></li>
<li class="chapter" data-level="6.3.3" data-path="ml-modeling.html"><a href="ml-modeling.html#select-models-based-on-interpretability-vs.-performance-trade-off"><i class="fa fa-check"></i><b>6.3.3</b> Select Models Based on Interpretability vs. Performance Trade-Off</a></li>
<li class="chapter" data-level="6.3.4" data-path="ml-modeling.html"><a href="ml-modeling.html#evaluate-model-complexity-and-training-time"><i class="fa fa-check"></i><b>6.3.4</b> Evaluate Model Complexity and Training Time</a></li>
<li class="chapter" data-level="6.3.5" data-path="ml-modeling.html"><a href="ml-modeling.html#experiment-and-cross-validation"><i class="fa fa-check"></i><b>6.3.5</b> Experiment and Cross-Validation</a></li>
<li class="chapter" data-level="6.3.6" data-path="ml-modeling.html"><a href="ml-modeling.html#consider-domain-knowledge-and-business-constraints"><i class="fa fa-check"></i><b>6.3.6</b> 6. <strong>Consider Domain Knowledge and Business Constraints</strong></a></li>
<li class="chapter" data-level="6.3.7" data-path="ml-modeling.html"><a href="ml-modeling.html#model-ensembling"><i class="fa fa-check"></i><b>6.3.7</b> 7. <strong>Model Ensembling</strong></a></li>
<li class="chapter" data-level="6.3.8" data-path="ml-modeling.html"><a href="ml-modeling.html#evaluate-and-iterate"><i class="fa fa-check"></i><b>6.3.8</b> 8. <strong>Evaluate and Iterate</strong></a></li>
<li class="chapter" data-level="6.3.9" data-path="ml-modeling.html"><a href="ml-modeling.html#deployment-considerations"><i class="fa fa-check"></i><b>6.3.9</b> 9. <strong>Deployment Considerations</strong></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="ml-modeling.html"><a href="ml-modeling.html#feature-selection"><i class="fa fa-check"></i><b>6.4</b> Feature Selection</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="ml-modeling.html"><a href="ml-modeling.html#recursive-feature-elimination-rfe"><i class="fa fa-check"></i><b>6.4.1</b> Recursive Feature Elimination (RFE)</a></li>
<li class="chapter" data-level="6.4.2" data-path="ml-modeling.html"><a href="ml-modeling.html#lasso-regularization"><i class="fa fa-check"></i><b>6.4.2</b> LASSO regularization</a></li>
<li class="chapter" data-level="6.4.3" data-path="ml-modeling.html"><a href="ml-modeling.html#mutual-information"><i class="fa fa-check"></i><b>6.4.3</b> Mutual Information</a></li>
<li class="chapter" data-level="6.4.4" data-path="ml-modeling.html"><a href="ml-modeling.html#mutual-information-vs-correlation-coefficient"><i class="fa fa-check"></i><b>6.4.4</b> Mutual information vs Correlation Coefficient</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ml-modeling.html"><a href="ml-modeling.html#important-features"><i class="fa fa-check"></i><b>6.5</b> Important Features</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="ml-modeling.html"><a href="ml-modeling.html#feature-importance-in-random-forest"><i class="fa fa-check"></i><b>6.5.1</b> Feature Importance in Random Forest</a></li>
<li class="chapter" data-level="6.5.2" data-path="ml-modeling.html"><a href="ml-modeling.html#using-feature-importance-for-selection"><i class="fa fa-check"></i><b>6.5.2</b> <strong>Using Feature Importance for Selection</strong></a></li>
<li class="chapter" data-level="6.5.3" data-path="ml-modeling.html"><a href="ml-modeling.html#advantages-of-using-random-forest-for-feature-selection"><i class="fa fa-check"></i><b>6.5.3</b> <strong>Advantages of Using Random Forest for Feature Selection</strong></a></li>
<li class="chapter" data-level="6.5.4" data-path="ml-modeling.html"><a href="ml-modeling.html#summary-4"><i class="fa fa-check"></i><b>6.5.4</b> <strong>Summary</strong></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ml-modeling.html"><a href="ml-modeling.html#fine-tuning-hyperparameters"><i class="fa fa-check"></i><b>6.6</b> Fine-tuning hyperparameters</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="ml-modeling.html"><a href="ml-modeling.html#key-hyperparameters-for-tree-based-models"><i class="fa fa-check"></i><b>6.6.1</b> Key Hyperparameters for Tree-Based Models</a></li>
<li class="chapter" data-level="6.6.2" data-path="ml-modeling.html"><a href="ml-modeling.html#fine-tuning-strategy"><i class="fa fa-check"></i><b>6.6.2</b> Fine-Tuning Strategy</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="ml-modeling.html"><a href="ml-modeling.html#cross-validation"><i class="fa fa-check"></i><b>6.7</b> Cross Validation</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="ml-modeling.html"><a href="ml-modeling.html#how-cross-validation-works"><i class="fa fa-check"></i><b>6.7.1</b> How Cross-Validation Works</a></li>
<li class="chapter" data-level="6.7.2" data-path="ml-modeling.html"><a href="ml-modeling.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>6.7.2</b> <strong>K-Fold Cross-Validation</strong></a></li>
<li class="chapter" data-level="6.7.3" data-path="ml-modeling.html"><a href="ml-modeling.html#advantages-of-k-fold-cross-validation"><i class="fa fa-check"></i><b>6.7.3</b> <strong>Advantages of K-Fold Cross-Validation:</strong></a></li>
<li class="chapter" data-level="6.7.4" data-path="ml-modeling.html"><a href="ml-modeling.html#choosing-the-value-of-k"><i class="fa fa-check"></i><b>6.7.4</b> <strong>Choosing the Value of <span class="math inline">\(k\)</span>:</strong></a></li>
<li class="chapter" data-level="6.7.5" data-path="ml-modeling.html"><a href="ml-modeling.html#alternative-methods"><i class="fa fa-check"></i><b>6.7.5</b> <strong>Alternative Methods:</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="model-evaluation.html"><a href="model-evaluation.html"><i class="fa fa-check"></i><b>7</b> Model Evaluation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="model-evaluation.html"><a href="model-evaluation.html#classification-models-evaluation"><i class="fa fa-check"></i><b>7.1</b> Classification Models: Evaluation</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="model-evaluation.html"><a href="model-evaluation.html#thresholding"><i class="fa fa-check"></i><b>7.1.1</b> Thresholding</a></li>
<li class="chapter" data-level="7.1.2" data-path="model-evaluation.html"><a href="model-evaluation.html#confusion-matrix"><i class="fa fa-check"></i><b>7.1.2</b> Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="model-evaluation.html"><a href="model-evaluation.html#roc-curve"><i class="fa fa-check"></i><b>7.2</b> ROC Curve</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="model-evaluation.html"><a href="model-evaluation.html#components-of-the-roc-curve"><i class="fa fa-check"></i><b>7.2.1</b> Components of the ROC Curve:</a></li>
<li class="chapter" data-level="7.2.2" data-path="model-evaluation.html"><a href="model-evaluation.html#how-to-read-the-roc-curve"><i class="fa fa-check"></i><b>7.2.2</b> How to Read the ROC Curve:</a></li>
<li class="chapter" data-level="7.2.3" data-path="model-evaluation.html"><a href="model-evaluation.html#area-under-the-roc-curve-auc"><i class="fa fa-check"></i><b>7.2.3</b> Area Under the ROC Curve (AUC):</a></li>
<li class="chapter" data-level="7.2.4" data-path="model-evaluation.html"><a href="model-evaluation.html#applications-of-roc-curve"><i class="fa fa-check"></i><b>7.2.4</b> Applications of ROC Curve:</a></li>
<li class="chapter" data-level="7.2.5" data-path="model-evaluation.html"><a href="model-evaluation.html#using-the-roc-curve-in-real-examples"><i class="fa fa-check"></i><b>7.2.5</b> Using the ROC Curve in Real Examples</a></li>
<li class="chapter" data-level="7.2.6" data-path="model-evaluation.html"><a href="model-evaluation.html#selecting-the-probability-threshold"><i class="fa fa-check"></i><b>7.2.6</b> Selecting the Probability Threshold:</a></li>
<li class="chapter" data-level="7.2.7" data-path="model-evaluation.html"><a href="model-evaluation.html#roc-curve-example"><i class="fa fa-check"></i><b>7.2.7</b> ROC Curve Example:</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="model-evaluation.html"><a href="model-evaluation.html#overfitting-1"><i class="fa fa-check"></i><b>7.3</b> Overfitting</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="model-evaluation.html"><a href="model-evaluation.html#how-do-you-overcome-overfitting"><i class="fa fa-check"></i><b>7.3.1</b> How Do You Overcome Overfitting?</a></li>
<li class="chapter" data-level="7.3.2" data-path="model-evaluation.html"><a href="model-evaluation.html#data-stratification-technique"><i class="fa fa-check"></i><b>7.3.2</b> Data Stratification Technique</a></li>
<li class="chapter" data-level="7.3.3" data-path="model-evaluation.html"><a href="model-evaluation.html#any-other-way-to-simplify-the-model"><i class="fa fa-check"></i><b>7.3.3</b> Any Other Way to Simplify the Model?</a></li>
<li class="chapter" data-level="7.3.4" data-path="model-evaluation.html"><a href="model-evaluation.html#are-you-using-cross-validation-method"><i class="fa fa-check"></i><b>7.3.4</b> 4. Are You Using Cross-Validation Method?</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="model-evaluation.html"><a href="model-evaluation.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>7.4</b> Bias-Variance Tradeoff</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="model-evaluation.html"><a href="model-evaluation.html#key-concepts-in-bias-variance-tradeoff"><i class="fa fa-check"></i><b>7.4.1</b> Key Concepts in Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="7.4.2" data-path="model-evaluation.html"><a href="model-evaluation.html#error-decomposition-and-tradeoff"><i class="fa fa-check"></i><b>7.4.2</b> Error Decomposition and Tradeoff</a></li>
<li class="chapter" data-level="7.4.3" data-path="model-evaluation.html"><a href="model-evaluation.html#managing-the-bias-variance-tradeoff"><i class="fa fa-check"></i><b>7.4.3</b> Managing the Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="7.4.4" data-path="model-evaluation.html"><a href="model-evaluation.html#conclusion"><i class="fa fa-check"></i><b>7.4.4</b> Conclusion</a></li>
<li class="chapter" data-level="7.4.5" data-path="model-evaluation.html"><a href="model-evaluation.html#lift-chart"><i class="fa fa-check"></i><b>7.4.5</b> Lift Chart</a></li>
<li class="chapter" data-level="7.4.6" data-path="model-evaluation.html"><a href="model-evaluation.html#roc-curve-receiver-operating-characteristic-curve"><i class="fa fa-check"></i><b>7.4.6</b> ROC Curve (Receiver Operating Characteristic Curve)</a></li>
<li class="chapter" data-level="7.4.7" data-path="model-evaluation.html"><a href="model-evaluation.html#summary-5"><i class="fa fa-check"></i><b>7.4.7</b> Summary</a></li>
<li class="chapter" data-level="7.4.8" data-path="model-evaluation.html"><a href="model-evaluation.html#bootstrapping"><i class="fa fa-check"></i><b>7.4.8</b> Bootstrapping</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="interview-questions.html"><a href="interview-questions.html"><i class="fa fa-check"></i><b>8</b> Interview Questions</a>
<ul>
<li class="chapter" data-level="8.0.1" data-path="interview-questions.html"><a href="interview-questions.html#tell-me-how-do-you-train-a-model-and-evaluate-it"><i class="fa fa-check"></i><b>8.0.1</b> tell me how do you train a model and evaluate it</a></li>
<li class="chapter" data-level="8.0.2" data-path="interview-questions.html"><a href="interview-questions.html#tell-me-how-you-can-use-llm-in-marketingheathcare"><i class="fa fa-check"></i><b>8.0.2</b> tell me how you can use LLM in marketing/heathcare</a></li>
<li class="chapter" data-level="8.0.3" data-path="interview-questions.html"><a href="interview-questions.html#objective-function-in-logistic-regression"><i class="fa fa-check"></i><b>8.0.3</b> objective function in logistic regression</a></li>
<li class="chapter" data-level="8.1" data-path="interview-questions.html"><a href="interview-questions.html#do-you-prefer-r-or-python"><i class="fa fa-check"></i><b>8.1</b> Do you prefer R or python?</a></li>
<li class="chapter" data-level="8.2" data-path="interview-questions.html"><a href="interview-questions.html#what-is-your-main-domain"><i class="fa fa-check"></i><b>8.2</b> What is your main domain?</a></li>
<li class="chapter" data-level="8.3" data-path="interview-questions.html"><a href="interview-questions.html#is-this-work-culture-fast-paced-do-you-deliver-value-quickly-or-what"><i class="fa fa-check"></i><b>8.3</b> Is this work culture fast-paced? Do you deliver value quickly or what?</a></li>
<li class="chapter" data-level="8.4" data-path="interview-questions.html"><a href="interview-questions.html#are-you-involved-in-any-efforts-convincing-business-stakeholders-to-adept-models-or-analysis-that-you-do"><i class="fa fa-check"></i><b>8.4</b> Are you involved in any efforts convincing business stakeholders to adept models or analysis that you do</a></li>
<li class="chapter" data-level="8.5" data-path="interview-questions.html"><a href="interview-questions.html#have-you-been-in-a-situation-where-you-feel-like-the-model-is-the-right-way-to-go-but-either-client-or-manager-that-you-need-to-convince"><i class="fa fa-check"></i><b>8.5</b> Have you been in a situation where you feel like the model is the right way to go but either client or manager that you need to convince?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="interview-prep.html"><a href="interview-prep.html"><i class="fa fa-check"></i><b>9</b> Interview Prep</a>
<ul>
<li class="chapter" data-level="9.1" data-path="interview-prep.html"><a href="interview-prep.html#look-alike-model-walk-thru"><i class="fa fa-check"></i><b>9.1</b> Look alike Model walk thru</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="interview-prep.html"><a href="interview-prep.html#situation"><i class="fa fa-check"></i><b>9.1.1</b> Situation</a></li>
<li class="chapter" data-level="9.1.2" data-path="interview-prep.html"><a href="interview-prep.html#task"><i class="fa fa-check"></i><b>9.1.2</b> Task</a></li>
<li class="chapter" data-level="9.1.3" data-path="interview-prep.html"><a href="interview-prep.html#action"><i class="fa fa-check"></i><b>9.1.3</b> Action</a></li>
<li class="chapter" data-level="9.1.4" data-path="interview-prep.html"><a href="interview-prep.html#result"><i class="fa fa-check"></i><b>9.1.4</b> Result</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://davutemrah.github.io/notebooks/" target="blank">Personal Repo Home</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ml-modeling" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> ML Modeling<a href="ml-modeling.html#ml-modeling" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="objective" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Objective<a href="ml-modeling.html#objective" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Business Problem</strong>: Describe the business need for the look-alike modeling project. For example, “The goal was to identify potential new customers who resemble our best-performing customers to optimize marketing campaigns and drive higher ROI.”</p>
</div>
<div id="data-processing" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Data Processing<a href="ml-modeling.html#data-processing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-collection" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Data collection<a href="ml-modeling.html#data-collection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>We started with two datasets: one for the high-value customers (labeled dataset) and another for the potential customers (scoring dataset).</p></li>
<li><p>The labeled dataset included demographic data, browsing behavior, engagement data, and other personal financial and interest attributes.</p></li>
<li><p>The scoring dataset contained the same types of features but did not include the target variable.</p></li>
</ul>
</div>
<div id="data-cleaning" class="section level3 hasAnchor" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Data Cleaning<a href="ml-modeling.html#data-cleaning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="missing-values" class="section level4 hasAnchor" number="6.2.2.1">
<h4><span class="header-section-number">6.2.2.1</span> Missing values<a href="ml-modeling.html#missing-values" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
<div id="outliers" class="section level4 hasAnchor" number="6.2.2.2">
<h4><span class="header-section-number">6.2.2.2</span> Outliers<a href="ml-modeling.html#outliers" class="anchor-section" aria-label="Anchor link to header"></a></h4>
</div>
</div>
<div id="feature-engineering" class="section level3 hasAnchor" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Feature Engineering<a href="ml-modeling.html#feature-engineering" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="correlated-features" class="section level4 hasAnchor" number="6.2.3.1">
<h4><span class="header-section-number">6.2.3.1</span> Correlated features<a href="ml-modeling.html#correlated-features" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>I used techniques like one-hot encoding for categorical variables and normalization for continuous variables to prepare the data for modeling.</p>
<ul>
<li><p><strong>Data</strong>:</p>
<ul>
<li><p>Explain how you cleaned and preprocessed the data. Mention any techniques used to handle missing values, outliers, or feature engineering.</p></li>
<li><p>For example, “”</p></li>
</ul></li>
<li><p><strong>Feature Selection</strong>:</p>
<ul>
<li>Discuss how you identified the key features that were most predictive of customer behavior. You might mention techniques like correlation analysis, feature importance from tree-based models, or principal component analysis (PCA).</li>
</ul></li>
<li><p><strong>Model Selection and Training</strong>:</p>
<ul>
<li>Describe the models you considered and why you chose the specific model for look-alike modeling. For instance, “I chose to use a Random Forest classifier because it handles high-dimensional data well and provides feature importance, which is valuable for understanding customer profiles.”</li>
<li>Mention how you trained the model, including any cross-validation techniques you used to ensure robustness.</li>
</ul></li>
<li><p><strong>Model Evaluation</strong>:</p>
<ul>
<li><p>Explain how you evaluated the model’s performance, using metrics like AUC-ROC, precision, recall, or F1 score.</p></li>
<li><p>For example, “I evaluated the model using AUC-ROC to measure its ability to distinguish between look-alike customers and non-look-alikes. The model achieved an AUC of 0.85, indicating strong predictive power.”</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="implementation-and-impact" class="section level3 hasAnchor" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> Implementation and Impact<a href="ml-modeling.html#implementation-and-impact" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Deployment</strong>:
<ul>
<li>Briefly describe how the model was deployed, whether it was integrated into a marketing platform, used to score new leads, or applied in a specific campaign.</li>
</ul></li>
<li><strong>Business Impact</strong>:
<ul>
<li>Highlight the results. For instance, “The look-alike model identified a segment of potential customers that, when targeted, led to a 20% increase in conversion rates compared to previous campaigns.”</li>
<li>If possible, provide metrics on ROI improvement or customer acquisition cost reduction.</li>
</ul></li>
</ul>
</div>
<div id="lessons-learned-and-future-work" class="section level3 hasAnchor" number="6.2.5">
<h3><span class="header-section-number">6.2.5</span> Lessons Learned and Future Work<a href="ml-modeling.html#lessons-learned-and-future-work" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Challenges</strong>:</p>
<ul>
<li>Discuss any challenges you faced, such as data limitations, model tuning difficulties, or integration issues.</li>
</ul></li>
<li><p><strong>Future Enhancements</strong>:</p>
<ul>
<li>Mention any improvements or next steps, like using more advanced models (e.g., gradient boosting machines), incorporating additional data sources, or refining the model based on new data.</li>
</ul></li>
</ul>

</div>
</div>
<div id="model-selection" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Model Selection<a href="ml-modeling.html#model-selection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Selecting the right model for a machine learning task depends on several factors, including the nature of the data, the problem to be solved (regression, classification, clustering, etc.), the performance metrics of interest, and the interpretability requirements. Here is a general process to help guide model selection:</p>
<div id="understand-the-problem-type" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Understand the Problem Type<a href="ml-modeling.html#understand-the-problem-type" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Regression</strong>: Predicting a continuous value (e.g., house prices, temperature).</p></li>
<li><p><strong>Classification</strong>: Predicting a discrete label (e.g., spam detection, sentiment analysis).</p></li>
<li><p><strong>Clustering</strong>: Grouping similar data points (e.g., customer segmentation).</p></li>
<li><p><strong>Anomaly Detection</strong>: Identifying unusual data points (e.g., fraud detection).</p></li>
</ul>
</div>
<div id="understand-the-data" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Understand the Data<a href="ml-modeling.html#understand-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Size of the Dataset</strong>: For small datasets, simpler models like linear regression or logistic regression might work better. For large datasets, more complex models like Random Forests or XGBoost can be effective.</p></li>
<li><p><strong>Data Quality and Distribution</strong>: Consider the amount of missing data, outliers, and feature scaling requirements. Some models are sensitive to these (e.g., SVMs, k-NN), while others are more robust (e.g., tree-based models).</p></li>
<li><p><strong>Feature Types</strong>: Handle categorical, continuous, text, or image data accordingly. Some models work better with specific data types.</p></li>
</ul>
</div>
<div id="select-models-based-on-interpretability-vs.-performance-trade-off" class="section level3 hasAnchor" number="6.3.3">
<h3><span class="header-section-number">6.3.3</span> Select Models Based on Interpretability vs. Performance Trade-Off<a href="ml-modeling.html#select-models-based-on-interpretability-vs.-performance-trade-off" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>High Interpretability</strong>: Linear regression, logistic regression, decision trees.</p></li>
<li><p><strong>Moderate to Low Interpretability, High Performance</strong>: Random Forest, Gradient Boosting Machines (GBM), XGBoost, CatBoost, LightGBM, Neural Networks.</p></li>
</ul>
</div>
<div id="evaluate-model-complexity-and-training-time" class="section level3 hasAnchor" number="6.3.4">
<h3><span class="header-section-number">6.3.4</span> Evaluate Model Complexity and Training Time<a href="ml-modeling.html#evaluate-model-complexity-and-training-time" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Simple models (e.g., linear regression, logistic regression) are quick to train and less prone to overfitting.</p></li>
<li><p>Complex models (e.g., deep learning models, ensemble methods) might offer higher accuracy but can require more time and computational resources.</p></li>
</ul>
</div>
<div id="experiment-and-cross-validation" class="section level3 hasAnchor" number="6.3.5">
<h3><span class="header-section-number">6.3.5</span> Experiment and Cross-Validation<a href="ml-modeling.html#experiment-and-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Use <strong>cross-validation</strong> (e.g., k-fold cross-validation) to evaluate model performance.</p></li>
<li><p>Perform <strong>hyperparameter tuning</strong> (e.g., Grid Search, Random Search, Bayesian Optimization) to optimize model parameters.</p></li>
<li><p>Compare models using relevant metrics (e.g., accuracy, precision, recall, F1-score for classification; MSE, MAE, R² for regression).</p></li>
</ul>
</div>
<div id="consider-domain-knowledge-and-business-constraints" class="section level3 hasAnchor" number="6.3.6">
<h3><span class="header-section-number">6.3.6</span> 6. <strong>Consider Domain Knowledge and Business Constraints</strong><a href="ml-modeling.html#consider-domain-knowledge-and-business-constraints" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Ensure the selected model aligns with the problem domain, interpretability needs, and deployment constraints (e.g., latency, scalability).</li>
</ul>
</div>
<div id="model-ensembling" class="section level3 hasAnchor" number="6.3.7">
<h3><span class="header-section-number">6.3.7</span> 7. <strong>Model Ensembling</strong><a href="ml-modeling.html#model-ensembling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Sometimes combining multiple models (e.g., stacking, bagging, boosting) yields better results than any single model.</li>
</ul>
</div>
<div id="evaluate-and-iterate" class="section level3 hasAnchor" number="6.3.8">
<h3><span class="header-section-number">6.3.8</span> 8. <strong>Evaluate and Iterate</strong><a href="ml-modeling.html#evaluate-and-iterate" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Evaluate the model on unseen test data and iterate as needed based on performance.</li>
</ul>
</div>
<div id="deployment-considerations" class="section level3 hasAnchor" number="6.3.9">
<h3><span class="header-section-number">6.3.9</span> 9. <strong>Deployment Considerations</strong><a href="ml-modeling.html#deployment-considerations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>Consider the complexity of deploying and maintaining the model, especially in production environments.</li>
</ul>
<p>Would you like to focus on a specific model or problem type for further details?</p>

</div>
</div>
<div id="feature-selection" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Feature Selection<a href="ml-modeling.html#feature-selection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Remove irrelevant or redundant features to reduce model complexity. Techniques like Recursive Feature Elimination (RFE), LASSO regularization, and mutual information can help identify important features.</p>
<div id="recursive-feature-elimination-rfe" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Recursive Feature Elimination (RFE)<a href="ml-modeling.html#recursive-feature-elimination-rfe" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="lasso-regularization" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> LASSO regularization<a href="ml-modeling.html#lasso-regularization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="mutual-information" class="section level3 hasAnchor" number="6.4.3">
<h3><span class="header-section-number">6.4.3</span> Mutual Information<a href="ml-modeling.html#mutual-information" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Mutual Information (MI)</strong> measures the amount of information obtained about one random variable through another random variable. In the context of feature selection in machine learning, it quantifies how much knowing the value of one feature reduces uncertainty about the target variable.</p>
<ul>
<li><p><strong>Definition</strong>:</p>
<ul>
<li>Mathematically, for two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the mutual information <span class="math inline">\(I(X; Y)\)</span> is defined as:</li>
</ul>
<p><span class="math display">\[
I(X; Y) = \sum_{x \in X} \sum_{y \in Y} P(x, y) \log \left( \frac{P(x, y)}{P(x) P(y)} \right)
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(P(x, y)\)</span> is the joint probability distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</li>
<li><span class="math inline">\(P(x)\)</span> and <span class="math inline">\(P(y)\)</span> are the marginal probability distributions of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, respectively.</li>
</ul></li>
<li><p><strong>Interpretation</strong>:</p>
<ul>
<li><p><strong>MI = 0</strong>: The two variables are independent; knowing one gives no information about the other.</p></li>
<li><p><strong>Higher MI</strong>: The two variables share more information. If MI is high, knowing one variable gives more information about the other.</p></li>
</ul></li>
<li><p><strong>Applications in Feature Selection</strong>:</p>
<ul>
<li>In machine learning, mutual information can be used to assess the relevance of a feature to the target variable. Features with high mutual information with the target are often more informative and can be prioritized in feature selection.</li>
</ul>
<p>This is a measure of <code>non-linear</code> relationships between variables and does not assume any specific type of dependency (linear or non-linear). <code>MI</code> is always non-negative and has no upper bound (though it can be normalized to fall between 0 and 1).</p></li>
</ul>
</div>
<div id="mutual-information-vs-correlation-coefficient" class="section level3 hasAnchor" number="6.4.4">
<h3><span class="header-section-number">6.4.4</span> Mutual information vs Correlation Coefficient<a href="ml-modeling.html#mutual-information-vs-correlation-coefficient" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>MI and the correlation coefficient are related but measure different aspects of the dependency between two variables.</p>
<p>MI is more general, capturing both linear and non-linear dependencies, while the correlation coefficient is limited to linear relationships.</p>
<p>If two variables are linearly related, the <code>mutual information</code> is closely related to the <code>correlation coefficient</code>. For normally distributed variables, <code>mutual information</code> can be directly calculated from the <code>correlation coefficient</code>.</p>
<p><code>Correlation</code> measures only linear dependency. It can miss non-linear relationships entirely. For example, a correlation of 0 does not mean there is no relationship; there might be a non-linear dependency.</p>
<p><code>Mutual Information</code> captures both linear and non-linear dependencies. Even if the correlation coefficient is 0, mutual information may still be high, indicating a non-linear relationship.</p>
<p><code>Correlation Coefficient</code> is simpler and computationally cheaper, widely used when linear relationships are expected or assumed, such as in linear regression or PCA.</p>
<p><code>Mutual Information</code> is more general and flexible, useful in scenarios like feature selection in machine learning, where both linear and non-linear relationships may be important.</p>
</div>
</div>
<div id="important-features" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Important Features<a href="ml-modeling.html#important-features" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Using a Random Forest model is actually a valid and commonly used technique. Here’s a detailed explanation of how feature importance is determined in Random Forest models and how it can be applied to feature selection:</p>
<div id="feature-importance-in-random-forest" class="section level3 hasAnchor" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Feature Importance in Random Forest<a href="ml-modeling.html#feature-importance-in-random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Feature Importance</strong> measures how much each feature contributes to the model’s predictive power. In a Random Forest, this is typically determined using the following methods:</p>
<ol style="list-style-type: decimal">
<li><strong>Mean Decrease in Impurity (MDI):</strong></li>
</ol>
<ul>
<li><p><strong>Concept:</strong> Random Forests are ensembles of decision trees. Each decision tree splits nodes based on features to minimize impurity (e.g., Gini impurity or entropy for classification; variance for regression). The more a feature helps to reduce impurity, the more important it is.</p></li>
<li><p><strong>Calculation:</strong> For each feature, compute the total reduction in impurity (weighted by the probability of reaching that node) across all trees in the forest. Average this reduction over all trees to determine feature importance.</p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Mean Decrease in Accuracy (MDA):</strong>
<ul>
<li><strong>Concept:</strong> This method involves permuting the values of a feature and measuring the decrease in model accuracy. A significant drop in accuracy indicates high importance of that feature.</li>
<li><strong>Calculation:</strong> For each feature, shuffle its values in the dataset and measure the performance drop of the model. The larger the drop, the more important the feature is.</li>
</ul></li>
</ol>
</div>
<div id="using-feature-importance-for-selection" class="section level3 hasAnchor" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> <strong>Using Feature Importance for Selection</strong><a href="ml-modeling.html#using-feature-importance-for-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Train a Random Forest Model:</strong>
<ul>
<li>Fit a Random Forest model to your data.</li>
<li>Compute feature importance scores using either MDI or MDA methods.</li>
</ul></li>
<li><strong>Rank Features:</strong>
<ul>
<li>Rank features based on their importance scores. Higher scores indicate more important features.</li>
</ul></li>
<li><strong>Select Top Features:</strong>
<ul>
<li>Choose a subset of the most important features based on your criteria (e.g., top 10%, top 20 features, or features with scores above a certain threshold).</li>
</ul></li>
<li><strong>Use Selected Features in Other Models:</strong>
<ul>
<li>Train and evaluate other models (e.g., Gradient Boosting Trees (GBT), XGBoost) using only the selected features.</li>
</ul></li>
</ol>
</div>
<div id="advantages-of-using-random-forest-for-feature-selection" class="section level3 hasAnchor" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> <strong>Advantages of Using Random Forest for Feature Selection</strong><a href="ml-modeling.html#advantages-of-using-random-forest-for-feature-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Non-linearity Handling:</strong> Random Forests can handle complex, non-linear relationships between features and the target variable.</li>
<li><strong>Robustness:</strong> They are less sensitive to noisy data and overfitting compared to some other feature selection methods.</li>
<li><strong>Automatic Ranking:</strong> The method provides a straightforward way to rank and select features based on their contribution to the model.</li>
</ul>
</div>
<div id="summary-4" class="section level3 hasAnchor" number="6.5.4">
<h3><span class="header-section-number">6.5.4</span> <strong>Summary</strong><a href="ml-modeling.html#summary-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Feature Importance:</strong> In a Random Forest, feature importance is determined by how much each feature contributes to reducing impurity or affecting model accuracy.</li>
<li><strong>Feature Selection:</strong> You can use feature importance scores from a Random Forest model to select the most relevant features for training other models, improving their performance and reducing complexity.</li>
</ul>
<p>Your approach is not only correct but also a practical way to enhance model performance and manage feature space efficiently.</p>

</div>
</div>
<div id="fine-tuning-hyperparameters" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Fine-tuning hyperparameters<a href="ml-modeling.html#fine-tuning-hyperparameters" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Fine-tuning hyperparameters is a crucial step in optimizing the performance of tree-based models like XGBoost, Random Forest, and CatBoost. Each hyperparameter controls a different aspect of the model’s behavior, and adjusting them properly can lead to better generalization on unseen data. Here’s a more detailed explanation of each hyperparameter and how it affects the model:</p>
<div id="key-hyperparameters-for-tree-based-models" class="section level3 hasAnchor" number="6.6.1">
<h3><span class="header-section-number">6.6.1</span> Key Hyperparameters for Tree-Based Models<a href="ml-modeling.html#key-hyperparameters-for-tree-based-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Number of Trees (n_estimators):</strong>
<ul>
<li><strong>Definition:</strong> This parameter determines the number of trees to be built in the ensemble. In Random Forest and XGBoost, each tree is built sequentially, and the results are aggregated.</li>
<li><strong>Impact:</strong> More trees generally lead to better model performance because they capture more patterns. However, too many trees can lead to overfitting, where the model becomes too tailored to the training data and loses its ability to generalize to new data.</li>
<li><strong>Tuning Strategy:</strong> Start with a moderate number of trees (e.g., 100) and gradually increase until the performance plateaus on validation data.</li>
</ul></li>
<li><strong>Learning Rate (eta in XGBoost, learning_rate in other models):</strong>
<ul>
<li><strong>Definition:</strong> The learning rate controls the contribution of each tree to the final prediction. A lower learning rate means that the model makes smaller updates and takes more trees to converge.</li>
<li><strong>Impact:</strong> A lower learning rate usually improves model performance because it allows for more fine-tuned adjustments. However, this comes at the cost of longer training times.</li>
<li><strong>Tuning Strategy:</strong> Common practice is to start with a low learning rate (e.g., 0.1) and, if the model underfits, increase it slightly. Alternatively, you can use a lower learning rate and compensate by increasing the number of trees.</li>
</ul></li>
<li><strong>Maximum Depth (max_depth):</strong>
<ul>
<li><strong>Definition:</strong> This parameter defines the maximum depth of each tree. A deeper tree can capture more complex patterns but is more likely to overfit the training data.</li>
<li><strong>Impact:</strong> Higher depth increases the model complexity, allowing it to capture more interactions between features. However, deeper trees can also lead to overfitting, especially with noisy data.</li>
<li><strong>Tuning Strategy:</strong> Start with a relatively shallow tree (e.g., max_depth of 3-6) and increase gradually. Monitor the validation performance to avoid overfitting.</li>
</ul></li>
<li><strong>Minimum Child Weight (min_child_weight):</strong>
<ul>
<li><strong>Definition:</strong> This parameter specifies the minimum sum of instance weights (hessian) needed in a child. It is a regularization parameter in XGBoost that prevents the algorithm from creating children that don’t have enough samples.</li>
<li><strong>Impact:</strong> Higher values prevent the algorithm from learning overly specific relations that can cause overfitting. It forces the tree to consider splitting only when a minimum number of observations exist in the child node.</li>
<li><strong>Tuning Strategy:</strong> Start with a lower value (e.g., 1) and gradually increase it to see if the model’s performance improves on validation data.</li>
</ul></li>
</ol>
</div>
<div id="fine-tuning-strategy" class="section level3 hasAnchor" number="6.6.2">
<h3><span class="header-section-number">6.6.2</span> Fine-Tuning Strategy<a href="ml-modeling.html#fine-tuning-strategy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Grid Search or Random Search:</strong>
<ul>
<li>Perform a <strong>grid search</strong> or <strong>random search</strong> over a defined range of hyperparameters. For example, grid search can test combinations like <code>n_estimators = [100, 200, 300]</code>, <code>learning_rate = [0.01, 0.05, 0.1]</code>, <code>max_depth = [3, 5, 7]</code>, and <code>min_child_weight = [1, 3, 5]</code>.</li>
<li><strong>Random search</strong> can be more efficient, especially when the parameter space is large, by randomly selecting combinations within the defined ranges.</li>
</ul></li>
<li><strong>Cross-Validation:</strong>
<ul>
<li>Use <strong>k-fold cross-validation</strong> to evaluate model performance during hyperparameter tuning. This approach splits the data into <code>k</code> subsets and trains the model <code>k</code> times, each time using a different subset as the validation set and the remaining as training data.</li>
</ul></li>
<li><strong>Early Stopping:</strong>
<ul>
<li>Implement <strong>early stopping</strong> during training to prevent overfitting. It stops training when the performance on the validation set no longer improves after a certain number of rounds, which is particularly useful when fine-tuning <code>n_estimators</code> and <code>learning_rate</code>.</li>
</ul></li>
<li><strong>Iterative Approach:</strong>
<ul>
<li>Start by tuning the most impactful hyperparameters like <code>learning_rate</code> and <code>n_estimators</code>. Once they are reasonably tuned, focus on regularization parameters like <code>max_depth</code> and <code>min_child_weight</code>.</li>
</ul></li>
</ol>
<p>By fine-tuning these hyperparameters systematically, we can improve the model’s accuracy and generalization, ensuring it performs well on unseen data without overfitting.</p>
<p>Would you like more details on any specific aspect?</p>

</div>
</div>
<div id="cross-validation" class="section level2 hasAnchor" number="6.7">
<h2><span class="header-section-number">6.7</span> Cross Validation<a href="ml-modeling.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Cross-validation</strong> is a technique used to assess how well a predictive model generalizes to an independent dataset. It is a crucial method in evaluating model performance and avoiding overfitting. Here’s a detailed explanation of how it works and its impact on overfitting:</p>
<div id="how-cross-validation-works" class="section level3 hasAnchor" number="6.7.1">
<h3><span class="header-section-number">6.7.1</span> How Cross-Validation Works<a href="ml-modeling.html#how-cross-validation-works" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Concept:</strong></li>
</ol>
<p>Cross-validation involves partitioning the dataset into multiple subsets or “folds.” The model is trained on some of these folds and tested on the remaining folds. This process is repeated several times, and each fold gets to be the test set once.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Common Types of Cross-Validation:</strong></li>
</ol>
<p><strong>k-Fold Cross-Validation:</strong></p>
<ul>
<li><p>The dataset is divided into <span class="math inline">\(k\)</span> equally-sized folds. The model is trained <span class="math inline">\(k\)</span> times, each time using <span class="math inline">\(k-1\)</span> folds for training and the remaining one fold for testing.</p></li>
<li><p>The performance metrics (e.g., accuracy, precision, recall) are averaged over all <span class="math inline">\(k\)</span> iterations to obtain an overall estimate of the model’s performance.</p></li>
</ul>
<p><strong>Leave-One-Out Cross-Validation (LOOCV):</strong></p>
<p>A special case of <span class="math inline">\(k\)</span>-fold cross-validation where <span class="math inline">\(k\)</span> equals the number of data points. Each data point is used once as a test set while the remaining <span class="math inline">\(n-1\)</span> points are used for training. This method is computationally expensive but useful for small datasets.</p>
<p><strong>Stratified k-Fold Cross-Validation:</strong></p>
<p>Similar to <span class="math inline">\(k\)</span>-fold cross-validation but ensures that each fold has approximately the same proportion of class labels as the original dataset, which is particularly useful for imbalanced datasets.</p>
<ul>
<li><strong>Time Series Cross-Validation:</strong>
<ul>
<li>For time series data, where temporal ordering is important, cross-validation is done in a way that respects the time sequence. This often involves using a rolling or expanding window approach.</li>
</ul></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><strong>Process:</strong></li>
</ol>
<ul>
<li><p><strong>Step 1:</strong> Split the dataset into <span class="math inline">\(k\)</span> folds.</p></li>
<li><p><strong>Step 2:</strong> For each fold, use it as a test set and the remaining <span class="math inline">\(k-1\)</span> folds as the training set.</p></li>
<li><p><strong>Step 3:</strong> Train the model on the training set and evaluate it on the test set.</p></li>
<li><p><strong>Step 4:</strong> Record the performance metric for each fold.</p></li>
<li><p><strong>Step 5:</strong> Average the performance metrics over all folds to obtain the overall model performance.</p></li>
</ul>
<p><strong>Summary:</strong></p>
<ul>
<li><p><strong>Cross-validation</strong> involves partitioning data into multiple folds, training and testing the model multiple times, and averaging performance metrics.</p></li>
<li><p>It helps assess how well a model generalizes to new data and is effective in identifying and reducing overfitting.</p></li>
<li><p>By using the entire dataset for both training and testing in various configurations, cross-validation provides a robust estimate of model performance and improves the reliability of the model evaluation process.</p></li>
<li><p>The term “test set” refers to the fold used to evaluate the model in each iteration.</p></li>
<li><p>This fold is sometimes referred to as the “validation set” during the cross-validation process.</p></li>
<li><p>A separate test set, not used in cross-validation, is often used for the final evaluation of the model after cross-validation.</p></li>
</ul>
<div id="impact-on-overfitting" class="section level4 hasAnchor" number="6.7.1.1">
<h4><span class="header-section-number">6.7.1.1</span> Impact on Overfitting<a href="ml-modeling.html#impact-on-overfitting" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Overfitting</strong> occurs when a model performs well on the training data but poorly on unseen data. Cross-validation helps mitigate overfitting in the following ways:</p>
<ol style="list-style-type: decimal">
<li><strong>Provides a More Reliable Estimate of Model Performance:</strong></li>
</ol>
<p>By evaluating the model on multiple different subsets of the data, cross-validation gives a better estimate of how the model performs on unseen data. This reduces the likelihood of the model fitting to peculiarities in a single training-test split.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Utilizes the Entire Dataset:</strong></li>
</ol>
<p>Cross-validation ensures that every data point is used for both training and testing. This maximizes the use of available data and helps in assessing model performance more thoroughly, thereby reducing the risk of overfitting to a particular subset.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Helps in Hyperparameter Tuning:</strong></li>
</ol>
<p>When tuning hyperparameters, cross-validation allows for more robust and unbiased estimation of the optimal settings. This prevents choosing parameters that only work well for a specific train-test split and generalizes better to new data.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Reduces Variability:</strong></li>
</ol>
<p>By averaging performance across multiple folds, cross-validation reduces the variability in performance estimates. This provides a more stable evaluation and helps in identifying models that generalize well across different subsets of data.</p>
</div>
<div id="best-model" class="section level4 hasAnchor" number="6.7.1.2">
<h4><span class="header-section-number">6.7.1.2</span> Best Model<a href="ml-modeling.html#best-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Selecting the best model during cross-validation involves evaluating the performance of different models or hyperparameter settings using cross-validation results. Here’s a detailed process on how this is typically done:</p>
<p><strong>1. Model Training and Evaluation with Cross-Validation</strong></p>
<p>A. <strong>Define Models and Hyperparameters:</strong>
- Identify the models you want to evaluate and the hyperparameters you want to tune. This could include different algorithms (e.g., decision trees, SVMs) and variations in hyperparameters (e.g., the number of trees in a random forest, the learning rate in gradient boosting).</p>
<p>B. <strong>Perform Cross-Validation:</strong>
- For each model or hyperparameter setting, perform <span class="math inline">\(k\)</span>-fold cross-validation:
- Split the dataset into <span class="math inline">\(k\)</span> folds.
- Train the model on <span class="math inline">\(k-1\)</span> folds and evaluate it on the remaining fold (the test set or validation set) for each iteration.
- Calculate performance metrics for each fold.</p>
<p>C. <strong>Aggregate Performance Metrics:</strong>
- For each model or hyperparameter setting, aggregate the performance metrics (e.g., accuracy, F1 score) from all <span class="math inline">\(k\)</span> folds. Common aggregation methods include:
- <strong>Mean:</strong> The average performance across all folds.
- <strong>Standard Deviation:</strong> Measures the variability of the model performance across folds.</p>
<p><strong>2. Selecting the Best Model</strong></p>
<p>A. <strong>Compare Aggregated Performance:</strong>
- Compare the mean performance metrics of different models or hyperparameter settings. The model with the best average performance is generally considered the best.</p>
<p>B. <strong>Check for Stability:</strong>
- Consider the stability of performance metrics. A model with low variance in performance across folds is preferable because it indicates consistent performance.</p>
<p>D. <strong>Analyze Overfitting and Underfitting:</strong>
- Ensure that the selected model is neither overfitting nor underfitting. Overfitting is indicated by a high performance on training folds but poor performance on validation folds. Underfitting is indicated by poor performance across all folds.</p>
<p>E. <strong>Hyperparameter Tuning:</strong>
- If hyperparameter tuning is involved, use cross-validation results to select the optimal hyperparameters. For example, use grid search or random search techniques to explore various hyperparameter combinations and choose the one that yields the best cross-validation performance.</p>
<p><strong>3. Final Model Evaluation</strong></p>
<p>A. <strong>Final Testing:</strong>
- After selecting the best model or hyperparameters, evaluate the final model on a completely separate test set that was not used during cross-validation. This provides an unbiased assessment of the model’s performance on new, unseen data.</p>
<p>B. <strong>Additional Validation:</strong>
- For critical applications, consider additional validation techniques such as:
- <strong>Nested Cross-Validation:</strong> For more robust hyperparameter tuning and model selection.
- <strong>Bootstrap Methods:</strong> To estimate the variability of performance metrics.</p>
<p><strong>Summary</strong></p>
<ul>
<li><p><strong>Train and evaluate</strong> multiple models or hyperparameter settings using cross-validation.</p></li>
<li><p><strong>Aggregate performance metrics</strong> from all folds to compare models.</p></li>
<li><p><strong>Select the best model</strong> based on mean performance and stability.</p></li>
<li><p><strong>Evaluate the final model</strong> on a separate test set to assess generalization to new data.</p></li>
</ul>
<p>By following this process, you ensure that the selected model is well-tuned, robust, and generalizes effectively to new data, reducing the risk of overfitting and improving overall model performance.</p>
<p>Cross-validation is a technique used to evaluate how well a machine learning model generalizes to unseen data. It helps ensure that the model is not just performing well on the training data but also on new, unseen data. Here’s a detailed explanation of <strong>k-fold cross-validation</strong>, one of the most commonly used methods:</p>
</div>
</div>
<div id="k-fold-cross-validation" class="section level3 hasAnchor" number="6.7.2">
<h3><span class="header-section-number">6.7.2</span> <strong>K-Fold Cross-Validation</strong><a href="ml-modeling.html#k-fold-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>Partitioning the Data:</strong>
<ul>
<li>The dataset is divided into <span class="math inline">\(k\)</span> equal (or nearly equal) parts, called <strong>folds</strong>.</li>
<li>For example, in 5-fold cross-validation, the data is split into 5 folds.</li>
</ul></li>
<li><strong>Training and Testing:</strong>
<ul>
<li>The model is trained <span class="math inline">\(k\)</span> times. Each time, one of the <span class="math inline">\(k\)</span> folds is used as the test set (validation set), while the remaining <span class="math inline">\(k-1\)</span> folds are used as the training set.</li>
<li>For instance, in a 5-fold cross-validation:
<ul>
<li><strong>First Iteration:</strong> The model is trained on folds 2, 3, 4, and 5, and tested on fold 1.</li>
<li><strong>Second Iteration:</strong> The model is trained on folds 1, 3, 4, and 5, and tested on fold 2.</li>
<li>This process continues until each fold has been used as a test set exactly once.</li>
</ul></li>
</ul></li>
<li><strong>Performance Metrics:</strong>
<ul>
<li>After all <span class="math inline">\(k\)</span> iterations, the model’s performance metrics (such as accuracy, precision, recall, etc.) are averaged to provide an overall performance estimate.</li>
<li>This average performance metric provides a better indication of the model’s generalization capability compared to a single train-test split.</li>
</ul></li>
</ol>
</div>
<div id="advantages-of-k-fold-cross-validation" class="section level3 hasAnchor" number="6.7.3">
<h3><span class="header-section-number">6.7.3</span> <strong>Advantages of K-Fold Cross-Validation:</strong><a href="ml-modeling.html#advantages-of-k-fold-cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Better Use of Data:</strong> Each data point is used for both training and testing, which maximizes the use of available data.</li>
<li><strong>Reduced Variability:</strong> It reduces the variability in performance estimates because the model is tested on multiple subsets of data.</li>
<li><strong>More Reliable Estimates:</strong> It provides a more reliable estimate of model performance compared to a single train-test split.</li>
</ul>
</div>
<div id="choosing-the-value-of-k" class="section level3 hasAnchor" number="6.7.4">
<h3><span class="header-section-number">6.7.4</span> <strong>Choosing the Value of <span class="math inline">\(k\)</span>:</strong><a href="ml-modeling.html#choosing-the-value-of-k" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Small <span class="math inline">\(k\)</span></strong> (e.g., <span class="math inline">\(k=5\)</span>): Provides a more reliable estimate but can be computationally less expensive.</li>
<li><strong>Large <span class="math inline">\(k\)</span></strong> (e.g., <span class="math inline">\(k=10\)</span>): Provides a more thorough evaluation but is computationally more intensive. A common choice is <span class="math inline">\(k=10\)</span> due to a good balance between computational efficiency and performance estimation.</li>
</ul>
</div>
<div id="alternative-methods" class="section level3 hasAnchor" number="6.7.5">
<h3><span class="header-section-number">6.7.5</span> <strong>Alternative Methods:</strong><a href="ml-modeling.html#alternative-methods" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Leave-One-Out Cross-Validation (LOOCV):</strong> A special case where <span class="math inline">\(k\)</span> is equal to the number of data points. Each data point is used as a test set once, and the model is trained on all remaining data points.</li>
<li><strong>Stratified K-Fold Cross-Validation:</strong> Ensures that each fold maintains the same distribution of class labels as the original dataset, which is especially useful for imbalanced datasets.</li>
</ul>
<p>By using cross-validation, you can get a robust evaluation of your model’s performance and help prevent overfitting, making sure your model will perform well on new, unseen data.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="extract-transform-loading.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="model-evaluation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/__Foundations/05_00_ml_modeling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Project_Archive.pdf", "Project_Archive.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
