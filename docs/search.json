[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"Hello ! 👋 devoted explorer navigating expansive realm machine learning, delighted present personal repository—virtual haven houses notes, musings, sample projects sourced diverse array blogs, books, practical encounters.curated collection serves mosaic insights, codes notes thoughtfully extracted publicly available machine learning blogs. project within repository testament ongoing quest understanding, meticulously pieced together rich tapestry digital knowledge landscape.Whether fellow enthusiast, curious mind, seasoned practitioner, extend invitation explore codebase, delve concepts, perhaps find inspiration machine learning journey. repository merely repository algorithms snippets; reflection commitment, curiosity, enthusiasm ever-evolving field machine learning.encourage engage, share thoughts, even collaborate journey. Let’s celebrate collaborative spirit machine learning community together, embrace boundless opportunities arise fusion code, data, collective wisdom publicly available resources.Happy exploration!","code":""},{"path":"projects.html","id":"projects","chapter":"1 Projects","heading":"1 Projects","text":"DataTab Statistics Tutorials","code":""},{"path":"projects.html","id":"notes-on-visuals","chapter":"1 Projects","heading":"1.0.1 NOTES ON VISUALS","text":"pre attentive principles, colurs, shape, size etc.pre attentive principles, colurs, shape, size etc.GESTALT principlesGESTALT principleswhy data visualization needed summary statistics. Data patterns may different although means may differentwhy data visualization needed summary statistics. Data patterns may different although means may differentexploratory graphs: may good people background. filtering control may given audienceexploratory graphs: may good people background. filtering control may given audienceexplanatory graphs: may good people backgroung. made simpleexplanatory graphs: may good people backgroung. made simple","code":""},{"path":"projects.html","id":"elastic-net-model","chapter":"1 Projects","heading":"1.1 Elastic Net Model","text":"Elastic Net regularization technique combines L1 (Lasso) L2 (Ridge) regularization penalties linear regression model. technique commonly used machine learning, especially dealing high-dimensional datasets situations features highly correlated.elastic net regularization, objective function combination L1 L2 regularization terms along linear regression loss. regularization strength controlled two hyperparameters, often denoted \nα\nα (alpha) \nλ\nλ (lambda):α\nα controls mixing L1 L2 regularization. \nα\n=\n0\nα=0, equivalent Ridge regression, \nα\n=\n1\nα=1, equivalent Lasso regression. value (0 1) allows mixture .\nλ\nλ controls overall strength regularization.R, can fit elastic net model using glmnet package. ’s brief example:","code":"\n# Install and load the glmnet package if not already installed\n# install.packages(\"glmnet\")\nlibrary(glmnet)\n\n# Generate some example data\nset.seed(42)\nn <- 100\np <- 10\nX <- matrix(rnorm(n * p), nrow = n, ncol = p)\nbeta_true <- c(2, 0, 1, 0, 0, 3, 0, 0, -2, 0)\ny <- X %*% beta_true + rnorm(n)\n\n# Fit an elastic net model\nalpha <- 0.5  # You can adjust alpha to control the mixture of L1 and L2 regularization\nlambda <- 0.1  # You can adjust lambda to control the overall strength of regularization\n\nenet_model <- cv.glmnet(X, y, alpha = alpha, lambda = lambda)"},{"path":"projects.html","id":"survival-analysis","chapter":"1 Projects","heading":"1.2 Survival Analysis","text":"","code":""},{"path":"projects.html","id":"references","chapter":"1 Projects","heading":"1.2.1 References","text":"Web SourcesEmily C. Zabor: Survival Aanalysis REmily C. Zabor: Survival Aanalysis RA short course Survival Analysis applied Financial IndustryA short course Survival Analysis applied Financial IndustrySurvival Analysis R BeginnersSurvival Analysis R BeginnersSurvival Analysis RSurvival Analysis RSurvival Analysis BasicsSurvival Analysis BasicsSteps perform Survival Analysis RSteps perform Survival Analysis RSurvival Analysis R, HarvardSurvival Analysis R, HarvardSurvival Analysis: Lisa Sullivan, PhDSurvival Analysis: Lisa Sullivan, PhDSurvival Analysis Part : Basic concepts first analysesSurvival Analysis Part : Basic concepts first analysesPractical Guide PaperPractical Guide PaperAn Introduction Survival Statistics: Kaplan-Meier AnalysisAn Introduction Survival Statistics: Kaplan-Meier AnalysisKaplan Meier curves: introductionKaplan Meier curves: introductionNCCTG Lung Cancer DataNCCTG Lung Cancer Datapdf references1. Data Setup Alternative2. Introduction Survival Analysis Practice3. Chapter 7 - Survival Models4. Notes Pat5. Parametric Survival Models6. Retain Customers Churn model7. Intro Survival Analysis","code":""},{"path":"projects.html","id":"time-to-event-analysis","chapter":"1 Projects","heading":"1.2.2 Time to event analysis","text":"Time event analysis also used widely social sciences interest analyzing time events job changes, marriage, birth children forth.certain aspects survival analysis data, censoring non-normality, generate great difficulty trying analyze data using traditional statistical models multiple linear regression.non-normality aspect data violates normality assumption commonly used statistical model regression ANOVA, etc.censored observation defined observation incomplete information.\nobservation right censored means information incomplete subject event time subject part study.point survival analysis follow subjects time observe point time experience event interest.often happens study span enough time order observe event subjects study. due number reasons. Perhaps subjects drop study reasons unrelated study (.e. patients moving another area leaving forwarding address).common feature examples subject able stay study possible observe time event eventually.Type censoring\n- Right truncation\n- Right censoring\n- Left truncation\n- Left censoringIn survival analysis, censoring refers situations event interest (e.g., death, failure, another outcome) observed subjects study period. two main types censoring: right truncation right censoring.Right Truncation:\nDefinition: Right truncation occurs individuals enter study different times, individuals already experienced event interest study begins.\nExample: Consider study time machine fails. study starts certain date, machines already failed date, machines considered right-truncated failure times observed study.\nDefinition: Right truncation occurs individuals enter study different times, individuals already experienced event interest study begins.Example: Consider study time machine fails. study starts certain date, machines already failed date, machines considered right-truncated failure times observed study.Right Censoring:\nDefinition: Right censoring occurs individuals followed certain period, event interest occur end study.\nExample: clinical trial studying time disease recurrence, patient experienced recurrence end study period lost follow-, survival time right-censored. exact time recurrence known patients.\nDefinition: Right censoring occurs individuals followed certain period, event interest occur end study.Example: clinical trial studying time disease recurrence, patient experienced recurrence end study period lost follow-, survival time right-censored. exact time recurrence known patients.summary, right truncation involves incomplete observation due subjects entering study late, whereas right censoring occurs event interest occurred subjects end study. types censoring common survival analysis need appropriately accounted statistical models obtain unbiased estimates survival probabilities hazard rates.survival data?Time--event data consist distinct start time end time.Examples cancer\n• Time surgery death\n• Time start treatment progression\n• Time response recurrenceExamples fieldsTime--event data common many fields including, limited \n• Time HIV infection development AIDS\n• Time heart attack\n• Time onset substance abuse\n• Time initiation sexual activity\n• Time machine malfunctionTypes censoringA subject may censored due :\n• Loss follow-\n• Withdrawal study\n• event end fixed study periodSpecifically examples right censoring.Left censoring interval censoring also possible, methods exist analyze type data.","code":""},{"path":"projects.html","id":"kaplan-meier","chapter":"1 Projects","heading":"1.2.3 Kaplan-Meier","text":"SourceThe Kaplan-Meier curve commonly used analyze time--event data, time death time specific event occurs. , Kaplan Meier curve graphically represent survival rate survival function. Time plotted x-axis survival rate plotted y-axis.","code":""},{"path":"projects.html","id":"survival-rate","chapter":"1 Projects","heading":"1.2.3.1 Survival rate","text":"Suppose ’re dental technician want study “survival time” filling tooth.start time moment person goes dentist filling, end time, event, moment filling breaks. time two events focus study.example, may interested probability filling last longer 5 years., read value 5 years graph, survival rate.5 years, Kaplan-Meier curve gives value 0.7.","code":"  So there is a 70% chance that your filling will last longer than 5 years."},{"path":"projects.html","id":"interpreting-the-kaplan-meier-curve","chapter":"1 Projects","heading":"1.2.3.2 Interpreting the Kaplan-Meier curve","text":"Kaplan-Meier curve shows cumulative survival probabilities.steeper slope indicates higher event rate (death rate) therefore worse survival prognosis. flatter slope indicates lower event rate therefore better survival prognosis. curve may plateaus flat areas, indicating periods relatively stable survival.multiple curves representing different groups, can compare shapes patterns. curves parallel, suggests groups similar survival experiences. curves diverge cross, indicates differences survival groups.specific time points, can estimate survival probability locating time point horizontal axis dropping vertical line curve. , read corresponding survival probability vertical axis.","code":""},{"path":"projects.html","id":"calculating-the-kaplan-meier-curve","chapter":"1 Projects","heading":"1.2.3.3 Calculating the Kaplan-Meier curve","text":"Let’s say filling lasted 3 years first subject, 4 years second subject, 4 years third subject, .Let’s assume none cases “censored”. data already arranged shortest survival time top longest bottom.Now create second table can use draw Kaplan-Meier curve. , look time points left table add time zero. time points 0, 3, 4, 6, 7, 8 11 13. total 10 subjects.Now look many fills break time. enter column m. time 0, fillings broken . 3 years, one broken fillings, 4 years two, 6 years one. now times.Next, look number cases survived time plus number cases event occurs exact time. enter column n.n number cases survived point, plus people dropped exact point.zero years still 10 people. 3 years, get 10 n, 9 people still fill intact, one person’s fill broke exactly 3 years.easiest way get n take previous n value subtract previous m value. get 10 - 1 equals 9. 9 minus 2 equals 7, 7 - 1 equals 6… forth.column n can now calculate survival rates. , simply divide n total number, .e. 10.10 divided 10 equal 1, 9 divided 10 equal 0.9, 7 divided 10 equal 0.7. Now others.","code":""},{"path":"projects.html","id":"draw-kaplan-meier-curve","chapter":"1 Projects","heading":"1.2.3.4 Draw Kaplan Meier curve","text":"can now plot Kaplan-Meier curve. time 0 value 1, 3 years value 0.9 90%. 4 years get 0.7, 6 years 0.6 forth.Kaplan-Meier curve, can now see percentage filling broken certain time.","code":""},{"path":"projects.html","id":"censored-data","chapter":"1 Projects","heading":"1.2.3.5 Censored data","text":"Censored data added example three places.now need enter data Kaplan-Meier curve table. follows: create m exactly , looking many cases failed time point.Now add column q, enter many cases censored time.Note time censored case occurred get row, assigned previous time.Let’s look case. censoring took place time 9. table, however, event nine years also don’t add . person added time 8.can now re-calculate values survival curve. censored data, little complex., write values first step. get values calculating n-m/n. third row, example, get value 10/12 12-2 12.calculation real value iterative. , multiply result previous row value just calculated., first row get 1, now calculate 12/13 times 1, equal 0.923. next row calculate 10/12 times 0.923 get value 0.769. take value next row.rows. can plot Kaplan-Meier curve data way .","code":""},{"path":"projects.html","id":"comparing-different-groups","chapter":"1 Projects","heading":"1.2.3.6 Comparing different groups","text":"comparing several groups categories (e.g. treatment groups), Kaplan-Meier curve consists several lines, representing different group. line shows estimated survival rate particular group. test whether statistically significant difference groups, log-rank test can used.several factors want see effect curve, can calculate Log Rank Test calculate Cox Regression DATAtab.","code":""},{"path":"projects.html","id":"kaplan-meier-curve-assumptions","chapter":"1 Projects","heading":"1.2.3.7 Kaplan-Meier curve assumptions","text":"Random Non-informative censoring: assumption states occurrence censoring unrelated likelihood experiencing event interest. words, censoring random influenced factors affect event outcome. censoring non-informative, estimated survival probabilities may biased.Independence censoring: assumption assumes censoring times different individuals independent . means occurrence timing censoring one participant provide information censoring times participants.Survival probabilities change time: Kaplan-Meier curve assumes survival probabilities estimated time point remain constant time. assumption may valid time-varying factors treatments can influence survival probabilities.competing risks: Kaplan-Meier curve assumes event interest possible outcome competing events prevent occurrence event studied. Competing events can include causes death events render occurrence event interest impossible.","code":""},{"path":"projects.html","id":"the-basics-of-survival-analysis","chapter":"1 Projects","heading":"1.2.4 The basics of Survival Analysis","text":"Original articleSurvival data time--event data consist distinct start time end time.Examples cancer:Time surgery deathTime start treatment progressionTime response recurrenceTime--event data common many fields.examples include:Time HIV infection development AIDSTime heart attackTime onset substance abuseTime initiation sexual activityTime machine malfunctionBecause time--event data common many fields, also goes names besides survival analysis including:Reliability analysisDuration analysisEvent history analysisTime--event analysisA key feature survival data censoring.Censoring occurs subject experienced event interest end data collection.subject may censored due :Loss follow-upWithdrawal studyNo event end fixed study periodSpecifically examples right censoring.Left censoring interval censoring also possible, methods exist analyze types data, tutorial focus right censoring.illustrate impact censoring, suppose following data:compute proportion event-free 10 years?Subjects 6 7 event-free 10 years.Subjects 2, 9, 10 event 10 years.Subjects 1, 3, 4, 5, 8 censored 10 years, don’t know whether event 10 years. know something - followed certain amount time without event interest prior censored.Survival analysis techniques provide way appropriately account censored patients analysis.lung datasetThroughout section, use lung dataset survival package example data. data contain subjects advanced lung cancer North Central Cancer Treatment Group. focus following variables throughout tutorial:Note status coded non-standard way dataset. Typically see 1=event, 0=censored. Let’s recode avoid confusion:Now :Note: Surv() function {survival} package accepts default TRUE/FALSE, TRUE event FALSE censored; 1/0 1 event 0 censored; 2/1 2 event 1 censored. Please take care ensure event indicator properly formatted.Calculating survival timesData often come start end dates rather pre-calculated survival times. first step make sure formatted dates R.Let’s create small example dataset variables sx_date surgery date last_fup_date last follow-date:see character variables, need formatted dates.use {lubridate} package work dates. case, need use ymd() function change format, since dates currently character format year comes first, followed month, followed day.Now dates formatted, need calculate difference start end dates units, usually months years. Using {lubridate} package, operator %--% designates time interval, converted number elapsed seconds using .duration() finally converted years dividing dyears(1), gives number seconds year.","code":"\nlibrary(knitr)\nlibrary(dplyr)\nlibrary(survival)\nlibrary(ggplot2)\nlibrary(tibble)\n\n# devtools::install_github(\"zabore/ezfun\")\nezfun::set_ccf_palette(\"contrast\")## <environment: R_GlobalEnv>\n# install.packages(c(\"lubridate\", \"ggsurvfit\", \"gtsummary\", \"tidycmprsk\"))\nlibrary(lubridate)## \n## Attaching package: 'lubridate'## The following objects are masked from 'package:base':\n## \n##     date, intersect, setdiff, union\nlibrary(ggsurvfit)\nlibrary(gtsummary)## #StandWithUkraine\nlibrary(tidycmprsk)## \n## Attaching package: 'tidycmprsk'## The following object is masked from 'package:gtsummary':\n## \n##     trial\n# devtools::install_github(\"zabore/condsurv\")\nlibrary(condsurv) **time:** Observed survival time in days\n **status:** censoring status 1=censored, 2=dead\n **sex:** 1=Male, 2=Female\nhead(lung[, c(\"time\", \"status\", \"sex\")])##   time status sex\n## 1  306      2   1\n## 2  455      2   1\n## 3 1010      1   1\n## 4  210      2   1\n## 5  883      2   1\n## 6 1022      1   1\nlung1 <- \n  lung %>% \n  mutate(\n    status = recode(status, '1' = 0, '2' = 1)\n  )\n\nhead(lung[, c(\"time\", \"status\", \"sex\")])##   time status sex\n## 1  306      2   1\n## 2  455      2   1\n## 3 1010      1   1\n## 4  210      2   1\n## 5  883      2   1\n## 6 1022      1   1time: Observed survival time in days\nstatus: censoring status 0=censored, 1=dead\nsex: 1=Male, 2=Female\ndate_ex <- \n  tibble(\n    sx_date = c(\"2007-06-22\", \"2004-02-13\", \"2010-10-27\"), \n    last_fup_date = c(\"2017-04-15\", \"2018-07-04\", \"2016-10-31\")\n    )\n\ndate_ex## # A tibble: 3 × 2\n##   sx_date    last_fup_date\n##   <chr>      <chr>        \n## 1 2007-06-22 2017-04-15   \n## 2 2004-02-13 2018-07-04   \n## 3 2010-10-27 2016-10-31\ndate_ex1 <-\n  date_ex %>% \n  mutate(\n    sx_date = ymd(sx_date), \n    last_fup_date = ymd(last_fup_date)\n    )\n\ndate_ex1## # A tibble: 3 × 2\n##   sx_date    last_fup_date\n##   <date>     <date>       \n## 1 2007-06-22 2017-04-15   \n## 2 2004-02-13 2018-07-04   \n## 3 2010-10-27 2016-10-31\ndate_ex2 <-\n  date_ex1 %>% \n  mutate(\n    observed_yrs = as.duration(sx_date %--% last_fup_date) / dyears(1)\n    )\n\ndate_ex2## # A tibble: 3 × 3\n##   sx_date    last_fup_date observed_yrs\n##   <date>     <date>               <dbl>\n## 1 2007-06-22 2017-04-15            9.82\n## 2 2004-02-13 2018-07-04           14.4 \n## 3 2010-10-27 2016-10-31            6.01"},{"path":"projects.html","id":"creating-survival-objects-and-curves","chapter":"1 Projects","heading":"1.2.4.1 Creating survival objects and curves","text":"Kaplan-Meier method common way estimate survival times probabilities. non-parametric approach results step function, step time event occurs.Lets see data :Surv() function {survival} package creates survival object use response model formula. one entry subject survival time, followed + subject censored.Let’s look first 10 observations:see subject 1 event time 306 days, subject 2 event time 455 days, subject 3 censored time 1010 days, etc.survfit() function creates survival curves using Kaplan-Meier method based formula. Let’s generate overall survival curve entire cohort, assign object s1, look structure using str():n: 228 subjects data.time: Distinct time points.n.risk: Number cases survived time plus number cases event occurs exact time.n.event: Number event happened time.","code":"\nlung[, c(\"time\", \"status\")][1:5, ]##   time status\n## 1  306      2\n## 2  455      2\n## 3 1010      1\n## 4  210      2\n## 5  883      2\nSurv(lung$time, lung$status)[1:10]##  [1]  306   455  1010+  210   883  1022+  310   361   218   166\ns1 <- survfit(Surv(time, status) ~ 1, data = lung)\nstr(s1)## List of 16\n##  $ n        : int 228\n##  $ time     : num [1:186] 5 11 12 13 15 26 30 31 53 54 ...\n##  $ n.risk   : num [1:186] 228 227 224 223 221 220 219 218 217 215 ...\n##  $ n.event  : num [1:186] 1 3 1 2 1 1 1 1 2 1 ...\n##  $ n.censor : num [1:186] 0 0 0 0 0 0 0 0 0 0 ...\n##  $ surv     : num [1:186] 0.996 0.982 0.978 0.969 0.965 ...\n##  $ std.err  : num [1:186] 0.0044 0.00885 0.00992 0.01179 0.01263 ...\n##  $ cumhaz   : num [1:186] 0.00439 0.0176 0.02207 0.03103 0.03556 ...\n##  $ std.chaz : num [1:186] 0.00439 0.0088 0.00987 0.01173 0.01257 ...\n##  $ type     : chr \"right\"\n##  $ logse    : logi TRUE\n##  $ conf.int : num 0.95\n##  $ conf.type: chr \"log\"\n##  $ lower    : num [1:186] 0.987 0.966 0.959 0.947 0.941 ...\n##  $ upper    : num [1:186] 1 1 0.997 0.992 0.989 ...\n##  $ call     : language survfit(formula = Surv(time, status) ~ 1, data = lung)\n##  - attr(*, \"class\")= chr \"survfit\""},{"path":"projects.html","id":"kaplan-meier-plotscurves","chapter":"1 Projects","heading":"1.2.4.2 Kaplan-Meier plots/Curves","text":"Kaplan Meier curve graphically represent survival rate survival function.use {ggsurvfit} package generate Kaplan-Meier plots.package aims ease plotting time--event endpoints using power {ggplot2} package. See http://www.danieldsjoberg.com/ggsurvfit/index.html details.Note: alternatively, survival plots can created using base R {survminer} package.{ggsurvfit} package works best create survfit object using included ggsurvfit::survfit2() function, uses syntax saw previously survival::survfit().ggsurvfit::survfit2() tracks environment function call, allows plot better default values labeling p-value reporting.default plot ggsurvfit() shows step function .can add confidence interval using add_confidence_interval():Typically also want see numbers risk table x-axis.can add using add_risktable():Plots can customized using many standard {ggplot2} options.","code":"\nsurvfit2(Surv(time, status) ~ 1, data = lung) %>% \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Overall survival probability\"\n  )\nsurvfit2(Surv(time, status) ~ 1, data = lung) %>% \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Overall survival probability\"\n  ) + \n  add_confidence_interval()\nsurvfit2(Surv(time, status) ~ 1, data = lung) %>% \n  ggsurvfit() +\n  labs(\n    x = \"Days\",\n    y = \"Overall survival probability\"\n    ) + \n  add_confidence_interval() +\n  add_risktable()"},{"path":"projects.html","id":"estimating-x-year-survival","chapter":"1 Projects","heading":"1.2.4.3 Estimating x-year survival","text":"One quantity often interest survival analysis probability surviving beyond certain number years, x.example, estimate probability surviving 1 year, use summary times argument\n(Note: time variable lung data actually days, need use times = 365.25)associated lower upper bounds 95% confidence interval also displayed.1-year survival probability point y-axis corresponds 1\nyear x-axis survival curve.happens use “naive” estimate? “naive” means patients censored prior 1-year considered event-free included denominator.121 228 patients lung data died 1 year “naive” estimate calculated :\\[(1−\\frac{121}{228})×100=47\\%\\]get incorrect estimate 1-year probability survival ignore fact 42 patients censored 1-year.Recall correct estimate 1-year probability survival, accounting censoring using Kaplan-Meier method, 41%.Ignoring censoring leads overestimate overall survival probability.Imagine two studies, 228 subjects. 165 deaths study. Censoring ignored one (blue line), censoring accounted (yellow line).censored subjects contribute information portion follow-time, fall risk set, thus pulling cumulative probability survival. Ignoring censoring erroneously treats patients censored part risk set entire follow-period.can produce nice tables x-time survival probability estimates using tbl_survfit() function {gtsummary} package:","code":"\nsummary(survfit(Surv(time, status) ~ 1, data = lung), times = 365.25)## Call: survfit(formula = Surv(time, status) ~ 1, data = lung)\n## \n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n##   365     65     121    0.409  0.0358        0.345        0.486We find that the 1-year probability of survival in this study is 41%.\nsurvfit(Surv(time, status) ~ 1, data = lung) %>% \n  tbl_survfit(\n    times = 365.25,\n    label_header = \"**1-year survival (95% CI)**\"\n  )"},{"path":"projects.html","id":"estimating-median-survival-time","chapter":"1 Projects","heading":"1.2.4.4 Estimating median survival time","text":"Another quantity often interest survival analysis average survival time, quantify using median. Survival times expected normally distributed mean appropriate summary.can obtain median survival directly survfit object:see median survival time 310 days lower upper bounds 95% confidence interval also displayed.Median survival time corresponding survival probability 0.5:happens use “naive” estimate? “naive” means exclude censored patients calculation entirely estimate median survival time among patients event.Summarize median survival time among 165 patients died:get incorrect estimate median survival time 284 days ignore fact censored patients also contribute follow-time.Recall correct estimate median survival time 310 days.Ignoring censoring lead underestimate median survival time follow-time censored patients contribute excluded (blue line). true survival curve accounting censoring lung data shown yellow comparison.can produce nice tables median survival time estimates using tbl_survfit() function {gtsummary} package:","code":"\nsurvfit(Surv(time, status) ~ 1, data = lung)## Call: survfit(formula = Surv(time, status) ~ 1, data = lung)\n## \n##        n events median 0.95LCL 0.95UCL\n## [1,] 228    165    310     285     363\nlung %>% \n  filter(status == 1) %>% \n  summarize(median_surv = median(time))##   median_surv\n## 1         284\nsurvfit(Surv(time, status) ~ 1, data = lung) %>% \n  tbl_survfit(\n    probs = 0.5,\n    label_header = \"**Median survival (95% CI)**\"\n  )"},{"path":"projects.html","id":"comparing-survival-times-between-groups","chapter":"1 Projects","heading":"1.2.4.5 Comparing survival times between groups","text":"can conduct -group significance tests using log-rank test.log-rank test equally weights observations entire follow-time common way compare survival times groups. versions heavily weight early late follow-appropriate depending research question (see ?survdiff different test options).get log-rank p-value using survdiff function. example, can test whether difference survival time according sex lung data:see significant difference overall survival according sex lung data, p-value p = 0.001.","code":"\nsurvdiff(Surv(time, status) ~ sex, data = lung)## Call:\n## survdiff(formula = Surv(time, status) ~ sex, data = lung)\n## \n##         N Observed Expected (O-E)^2/E (O-E)^2/V\n## sex=1 138      112     91.6      4.55      10.3\n## sex=2  90       53     73.4      5.68      10.3\n## \n##  Chisq= 10.3  on 1 degrees of freedom, p= 0.001\nrequire(\"survival\")\nlibrary(\"survminer\")\n\nfit <- survfit(Surv(time, status) ~ sex, data = lung)\n\nggsurvplot(fit, data = lung)\nggsurvplot(\n  fit,\n  data = lung,\n  size = 1,                 # change line size\n  palette =\n    c(\"#E7B800\", \"#2E9FDF\"),# custom color palettes\n  conf.int = TRUE,          # Add confidence interval\n  pval = TRUE,              # Add p-value\n  risk.table = TRUE,        # Add risk table\n  risk.table.col = \"strata\",# Risk table color by groups\n  legend.labs =\n    c(\"Male\", \"Female\"),    # Change legend labels\n  risk.table.height = 0.25, # Useful to change when you have multiple groups\n  ggtheme = theme_bw()      # Change ggplot2 theme\n)"},{"path":"projects.html","id":"the-cox-regression-model","chapter":"1 Projects","heading":"1.2.4.6 The Cox regression model","text":"may want quantify effect size single variable, include one variable regression model account effects multiple variables.Cox regression model semi-parametric model can used fit univariable multivariable regression models survival outcomes.\\[h(t|Xi)=h0(t)exp(β1Xi1+⋯+βpXip)\\]\\(h(t)\\)\nhazard, instantaneous rate events occur h0(t)\n\nunderlying baseline hazard\nkey assumptions model:non-informative censoring\nproportional hazardsNote: parametric regression models survival outcomes also available, won’t addressed .can fit regression models survival data using coxph() function {survival} package, takes Surv() object left hand side standard syntax regression formulas R right hand side.can obtain tables results using tbl_regression() function {gtsummary} package, option exponentiate set TRUE return hazard ratio rather log hazard ratio:quantity interest Cox regression model hazard ratio (HR). HR represents ratio hazards two groups particular point time.HR interpreted instantaneous rate occurrence event interest still risk event. risk, though commonly mis-interpreted . regression parameter β, \\(HR = exp(β)\\)HR < 1 indicates reduced hazard death whereas HR > 1 indicates increased hazard death.HR = 0.59 implies 0.59 times many females dying males, given time. Stated differently, females significantly lower hazard death males data.","code":"\ncoxph(Surv(time, status) ~ sex, data = lung)## Call:\n## coxph(formula = Surv(time, status) ~ sex, data = lung)\n## \n##        coef exp(coef) se(coef)      z       p\n## sex -0.5310    0.5880   0.1672 -3.176 0.00149\n## \n## Likelihood ratio test=10.63  on 1 df, p=0.001111\n## n= 228, number of events= 165\ncoxph(Surv(time, status) ~ sex, data = lung) %>% \n  tbl_regression(exp = TRUE)"},{"path":"projects.html","id":"prosper-loan-data","chapter":"1 Projects","heading":"1.2.5 Prosper Loan data","text":"","code":"\nlibrary(data.table)## \n## Attaching package: 'data.table'## The following objects are masked from 'package:lubridate':\n## \n##     hour, isoweek, mday, minute, month, quarter, second, wday, week,\n##     yday, year## The following objects are masked from 'package:dplyr':\n## \n##     between, first, last\n# web <- \"https://s3.amazonaws.com/udacity-hosted-downloads/ud651/prosperLoanData.csv\"\n# loan <- fread(web)\n\n# head(loan)[, c(51, 65, 6, 7, 19, 18, 50)]"},{"path":"projects.html","id":"customer-churn","chapter":"1 Projects","heading":"1.2.6 Customer Churn","text":"usually costs acquire customer retain customer.Focusing customer retention enables companies maximize customer revenue lifetime.models seldom done optimally rely binary classification flags (churn yes ). Churn classification models tell customer likely leave indicate ’s going happen within certain number days months.churn classification model, don’t usually account differences time.probably mistake treat customer risk leaving 40 days customer remains 100 days. Traditional churn modeling make differentiation.fails account time, clear idea point marketing intervention needed causes preventable customer attrition.point time “within 40 days” threshold. fails account time, clear idea point marketing intervention needed causes preventable customer attrition.","code":""},{"path":"projects.html","id":"re-framing-the-problem-to-know-when","chapter":"1 Projects","heading":"1.2.6.1 Re-framing the Problem to Know When","text":"Rather use binary classifier, going re-frame problem time-dependent one. enables us intervene right time stop customer attrition happens.longer relying thresholds, now set churn continuous time conditioned event. graph shows, now know time attrition risk likely happen.longer time held constant, now track risk time determine marketing intervention needed retain customer.model time event, right moment intervene prevent attrition apparent. modeling technique called Survival Analysis allows us advent modern Machine Learning, ’s now trivial task.Survival models data different traditional classification problem requires:\n- Censor — purposes customers ’ve yet churn. Read right censoring .Duration — duration time t customer’s activity. case, ’s Account Length days.Duration — duration time t customer’s activity. case, ’s Account Length days.Event — binary target, case terminated phone plan marked Churn? .Event — binary target, case terminated phone plan marked Churn? .plot, red lines indicates customer left dots indicating specific point time.Blue lines customers still active time measured x-axis Duration.see customer number 8 attrit 195 days, customer numbers 0 4 leaving 163 146 days respectively. customers still active.Notice customers set time scale data analytically aligned. customer might come different times ’ve set days .allowed us right-censor data churn event. Real world data needs censoring aligning modeling can begin.","code":"# %reload_ext autoreload\n# %autoreload 2\n# %matplotlib inline\n\nimport xgboost as xgb\nimport shap\nimport sksurv.metrics as surv_metrics\nfrom sksurv.datasets import get_x_y\nfrom lifelines import KaplanMeierFitter\nfrom lifelines.plotting import plot_lifetimes\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.exceptions import DataConversionWarning\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n\n\nplt.rcParams['figure.figsize'] = [7.2, 4.8]\npd.set_option(\"display.float_format\", lambda x: \"%.4f\" % x)\n\nsns.set_style('darkgrid')\n\nSEED = 123df = pd.read_csv(\"../../data/churn.txt\")\n# denoting churn and duration\ndf[\"event\"] = np.where(df[\"churn?\"] == \"False.\", 0, 1) \ndf = df.rename(columns={\"account_length\": \"duration\"})\ndel df['churn?']\ndf = df.dropna()\ndf = df.drop_duplicates()\ndf.head()print(\"Total Records:\",df.shape[0],\"\\n\")\nprint(\"Percent Churn Rate:\",df.event.mean())\nprint(\"\")\nprint(\"Duration Intervals\")\nprint(df['duration'].describe())ax = plot_lifetimes(df.head(10)['duration'], df.head(10)['event'])\n_=ax.set_xlabel(\"Duration: Account Length (days)\") _=ax.set_ylabel(\"Customer Number\") _=ax.set_title(\"Observed Customer Attrition\")"},{"path":"projects.html","id":"the-risk-of-churn","chapter":"1 Projects","heading":"1.2.6.2 The Risk of Churn","text":"informative approach might estimate Survival Function time days customer attrit. purpose, use Kaplan Meier Estimator calculate long attrition occurs. estimator defined :\\(𝑑_𝑖\\) number churn events time \\(𝑡\\) \\(𝑛_𝑖\\) number customers risk churn just prior time \\(𝑡\\).use great python package lifelines plot Survival Function function component final churn model.Let’s look median survival time. point half customers churned . According graph, ’s marked red dotted line, 152 days half customers churn.helpful gives overall baseline intervention needed. However, individual customer uninformative.\nmissing point time churn risk highest customer.create model using Cox’s Proportional Hazard uses log-risk function \\(h(x)\\). Hazard function conditioned rate customers remaining time t later, allows estimate risk churn overtime.enable us score customer anticipate marketing intervention needed. However, proceed , need preprocess data.","code":"kmf = KaplanMeierFitter()\nkmf.fit(df['duration'], event_observed=df['event'])\nkmf.plot_survival_function()\n\n_=plt.title('Survival Function for Telco Churn'); _=plt.xlabel(\"Duration: Account Length (days)\")\n_=plt.ylabel(\"Churn Risk (Percent Churned)\") \n_=plt.axvline(x=kmf.median_survival_time_, color='r',linestyle='--')"},{"path":"projects.html","id":"data-splitting-and-preprocessing","chapter":"1 Projects","heading":"1.2.6.3 Data Splitting and Preprocessing","text":"First split data training testing. ’ll use testing set validation example.Next, take numeric features categorical features preprocess downstream modeling.case categories, first impute constant simply one-hot encode . case numerics, fill median standardize values 0 1. wrapped Sklearn’s Pipeline ColumnTransformer simplicity’s sake.\npart Churn Pipeline steps included final preprocessor saved use inference time.","code":"In practice, you want all three of these splits so that you don’t tune to the validation set."},{"path":"projects.html","id":"deploying-a-scalable-end-to-end-customer-churn-prediction-solution-with-aws","chapter":"1 Projects","heading":"1.2.7 Deploying a Scalable End to End Customer Churn Prediction Solution with AWS","text":"SourceWouldn’t great hold onto customers longer, maximizing lifetime revenue?blog post, deploy End End Customer Churn Prediction solution using AWS services.","code":"import findspark\nfindspark.init()from pyspark.sql import SparkSession\nfrom pyspark import SparkFiles\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.feature import VectorAssemblermy_appname = \"LogisticRegression with PySpark MLlib\"\nspark = SparkSession.builder.appName(my_appname).getOrCreate()# Load data\nurl = \"https://raw.githubusercontent.com/pkmklong/Breast-Cancer-Wisconsin-Diagnostic-DataSet/master/data.csv\"\nspark.sparkContext.addFile(url)\n\ndf = spark.read.csv(SparkFiles.get(\"data.csv\"), header=True, inferSchema=True)\n\n# df.show()# Rename columns and map diagnosis to label\ncolumns = ['id', 'diagnosis'] + [f'feature_{i}' for i in range(1, 32)]\ndata = df.toDF(*columns)\ndata = data.withColumn(\"label\", (data[\"diagnosis\"] == \"M\").cast(\"integer\")).drop(\"diagnosis\")# Assemble features into a single vector\nfeature_columns = [f'feature_{i}' for i in range(1, 25)]\nassembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\ndata = assembler.transform(data)# Split data into training and test sets\ntrain_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n\n# Build the Logistic Regression model\nlogistic_regression = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\nmodel = logistic_regression.fit(train_data)# Evaluate the model on test data\npredictions = model.transform(test_data)# AUC-ROC\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"label\")\nauc = evaluator.evaluate(predictions)# Accuracy, Precision, and Recall\nmulti_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\naccuracy = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"accuracy\"})\nprecision = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedPrecision\"})\nrecall = multi_evaluator.evaluate(predictions, {multi_evaluator.metricName: \"weightedRecall\"})\n\nprint(f\"AUC-ROC: {auc:.4f}\")## AUC-ROC: 0.9989print(f\"Accuracy: {accuracy:.4f}\")## Accuracy: 0.9651print(f\"Precision: {precision:.4f}\")## Precision: 0.9653print(f\"Recall: {recall:.4f}\")## Recall: 0.9651"}]
