<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Machine Learning Fundamentals | Machine Learning</title>
  <meta name="description" content="This is a collection of notes to my self" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Machine Learning Fundamentals | Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a collection of notes to my self" />
  <meta name="github-repo" content="davutemrah/davutemrah.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Machine Learning Fundamentals | Machine Learning" />
  
  <meta name="twitter:description" content="This is a collection of notes to my self" />
  

<meta name="author" content="Davut Ayan" />


<meta name="date" content="2025-01-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="projects.html"/>
<link rel="next" href="machine-learning-fundementals.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="projects.html"><a href="projects.html"><i class="fa fa-check"></i><b>1</b> Projects</a></li>
<li class="chapter" data-level="2" data-path="machine-learning-fundamentals.html"><a href="machine-learning-fundamentals.html"><i class="fa fa-check"></i><b>2</b> Machine Learning Fundamentals</a>
<ul>
<li class="chapter" data-level="2.1" data-path="machine-learning-fundamentals.html"><a href="machine-learning-fundamentals.html#definitions"><i class="fa fa-check"></i><b>2.1</b> definitions</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="machine-learning-fundamentals.html"><a href="machine-learning-fundamentals.html#data-science"><i class="fa fa-check"></i><b>2.1.1</b> Data Science</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html"><i class="fa fa-check"></i><b>3</b> Machine Learning Fundementals</a>
<ul>
<li class="chapter" data-level="3.1" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#overfitting"><i class="fa fa-check"></i><b>3.1</b> Overfitting</a></li>
<li class="chapter" data-level="3.2" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#underfitting"><i class="fa fa-check"></i><b>3.2</b> Underfitting</a></li>
<li class="chapter" data-level="3.3" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>3.3</b> Bias-Variance Trade-off</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#bias"><i class="fa fa-check"></i><b>3.3.1</b> Bias</a></li>
<li class="chapter" data-level="3.3.2" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#variance"><i class="fa fa-check"></i><b>3.3.2</b> Variance</a></li>
<li class="chapter" data-level="3.3.3" data-path="machine-learning-fundementals.html"><a href="machine-learning-fundementals.html#bias-vs.-variance-trade-off"><i class="fa fa-check"></i><b>3.3.3</b> Bias vs.Â Variance Trade-Off:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>4</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="machine-learning.html"><a href="machine-learning.html#ml-algorithms-intro"><i class="fa fa-check"></i><b>4.1</b> ML Algorithms Intro</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="machine-learning.html"><a href="machine-learning.html#binary-classification"><i class="fa fa-check"></i><b>4.1.1</b> Binary Classification:</a></li>
<li class="chapter" data-level="4.1.2" data-path="machine-learning.html"><a href="machine-learning.html#multi-class-classification"><i class="fa fa-check"></i><b>4.1.2</b> Multi-Class Classification:</a></li>
<li class="chapter" data-level="4.1.3" data-path="machine-learning.html"><a href="machine-learning.html#continuous-outcome-regression"><i class="fa fa-check"></i><b>4.1.3</b> Continuous Outcome (Regression):</a></li>
<li class="chapter" data-level="4.1.4" data-path="machine-learning.html"><a href="machine-learning.html#random-forest-vs-decision-trees"><i class="fa fa-check"></i><b>4.1.4</b> Random Forest vs Decision Trees</a></li>
<li class="chapter" data-level="4.1.5" data-path="machine-learning.html"><a href="machine-learning.html#random-forest-vs-gradient-boosting"><i class="fa fa-check"></i><b>4.1.5</b> Random Forest vs Gradient Boosting</a></li>
<li class="chapter" data-level="4.1.6" data-path="machine-learning.html"><a href="machine-learning.html#overall-considerations"><i class="fa fa-check"></i><b>4.1.6</b> Overall Considerations:</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="machine-learning.html"><a href="machine-learning.html#ml-libraries-in-python"><i class="fa fa-check"></i><b>4.2</b> ML Libraries in Python</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="machine-learning.html"><a href="machine-learning.html#tensorflow"><i class="fa fa-check"></i><b>4.2.1</b> TensorFlow</a></li>
<li class="chapter" data-level="4.2.2" data-path="machine-learning.html"><a href="machine-learning.html#pytorch"><i class="fa fa-check"></i><b>4.2.2</b> PyTorch</a></li>
<li class="chapter" data-level="4.2.3" data-path="machine-learning.html"><a href="machine-learning.html#big-data-solutions"><i class="fa fa-check"></i><b>4.2.3</b> Big data solutions</a></li>
<li class="chapter" data-level="4.2.4" data-path="machine-learning.html"><a href="machine-learning.html#databricks"><i class="fa fa-check"></i><b>4.2.4</b> Databricks</a></li>
<li class="chapter" data-level="4.2.5" data-path="machine-learning.html"><a href="machine-learning.html#tensorflow-1"><i class="fa fa-check"></i><b>4.2.5</b> TensorFlow</a></li>
<li class="chapter" data-level="4.2.6" data-path="machine-learning.html"><a href="machine-learning.html#pytorch-1"><i class="fa fa-check"></i><b>4.2.6</b> PyTorch</a></li>
<li class="chapter" data-level="4.2.7" data-path="machine-learning.html"><a href="machine-learning.html#hadoop"><i class="fa fa-check"></i><b>4.2.7</b> Hadoop</a></li>
<li class="chapter" data-level="4.2.8" data-path="machine-learning.html"><a href="machine-learning.html#pyspark"><i class="fa fa-check"></i><b>4.2.8</b> PySpark</a></li>
<li class="chapter" data-level="4.2.9" data-path="machine-learning.html"><a href="machine-learning.html#summary"><i class="fa fa-check"></i><b>4.2.9</b> Summary</a></li>
<li class="chapter" data-level="4.2.10" data-path="machine-learning.html"><a href="machine-learning.html#ensemble-learning-in-machine-learning"><i class="fa fa-check"></i><b>4.2.10</b> <strong>Ensemble Learning in Machine Learning</strong></a></li>
<li class="chapter" data-level="4.2.11" data-path="machine-learning.html"><a href="machine-learning.html#key-concepts-of-ensemble-learning"><i class="fa fa-check"></i><b>4.2.11</b> <strong>Key Concepts of Ensemble Learning:</strong></a></li>
<li class="chapter" data-level="4.2.12" data-path="machine-learning.html"><a href="machine-learning.html#bagging-bootstrap-aggregating"><i class="fa fa-check"></i><b>4.2.12</b> <strong>1. Bagging (Bootstrap Aggregating):</strong></a></li>
<li class="chapter" data-level="4.2.13" data-path="machine-learning.html"><a href="machine-learning.html#boosting"><i class="fa fa-check"></i><b>4.2.13</b> <strong>2. Boosting:</strong></a></li>
<li class="chapter" data-level="4.2.14" data-path="machine-learning.html"><a href="machine-learning.html#stacking-stacked-generalization"><i class="fa fa-check"></i><b>4.2.14</b> <strong>3. Stacking (Stacked Generalization):</strong></a></li>
<li class="chapter" data-level="4.2.15" data-path="machine-learning.html"><a href="machine-learning.html#other-ensemble-methods"><i class="fa fa-check"></i><b>4.2.15</b> <strong>Other Ensemble Methods:</strong></a></li>
<li class="chapter" data-level="4.2.16" data-path="machine-learning.html"><a href="machine-learning.html#advantages-of-ensemble-learning"><i class="fa fa-check"></i><b>4.2.16</b> <strong>Advantages of Ensemble Learning:</strong></a></li>
<li class="chapter" data-level="4.2.17" data-path="machine-learning.html"><a href="machine-learning.html#disadvantages-of-ensemble-learning"><i class="fa fa-check"></i><b>4.2.17</b> <strong>Disadvantages of Ensemble Learning:</strong></a></li>
<li class="chapter" data-level="4.2.18" data-path="machine-learning.html"><a href="machine-learning.html#summary-1"><i class="fa fa-check"></i><b>4.2.18</b> <strong>Summary:</strong></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="machine-learning.html"><a href="machine-learning.html#regularization"><i class="fa fa-check"></i><b>4.3</b> Regularization</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="machine-learning.html"><a href="machine-learning.html#lasso-regression"><i class="fa fa-check"></i><b>4.3.1</b> Lasso Regression</a></li>
<li class="chapter" data-level="4.3.2" data-path="machine-learning.html"><a href="machine-learning.html#bayesian-models"><i class="fa fa-check"></i><b>4.3.2</b> Bayesian Models</a></li>
<li class="chapter" data-level="4.3.3" data-path="machine-learning.html"><a href="machine-learning.html#correlation-between-lasso-and-bayesian-models"><i class="fa fa-check"></i><b>4.3.3</b> Correlation Between Lasso and Bayesian Models</a></li>
<li class="chapter" data-level="4.3.4" data-path="machine-learning.html"><a href="machine-learning.html#summary-2"><i class="fa fa-check"></i><b>4.3.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="machine-learning.html"><a href="machine-learning.html#logistic-regression-key-concepts-for-data-science-interviews"><i class="fa fa-check"></i><b>4.4</b> Logistic Regression: Key Concepts for Data Science Interviews</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="machine-learning.html"><a href="machine-learning.html#what-you-need-to-know"><i class="fa fa-check"></i><b>4.4.1</b> What You Need to Know:</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="machine-learning.html"><a href="machine-learning.html#gradient-boosting-trees-gbt"><i class="fa fa-check"></i><b>4.5</b> Gradient Boosting Trees (GBT)</a></li>
<li class="chapter" data-level="4.6" data-path="machine-learning.html"><a href="machine-learning.html#random-forest-2"><i class="fa fa-check"></i><b>4.6</b> Random Forest</a></li>
<li class="chapter" data-level="4.7" data-path="machine-learning.html"><a href="machine-learning.html#xgboost-key-concepts-for-data-science-interviews"><i class="fa fa-check"></i><b>4.7</b> XGBoost: Key Concepts for Data Science Interviews</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="machine-learning.html"><a href="machine-learning.html#what-you-need-to-know-1"><i class="fa fa-check"></i><b>4.7.1</b> What You Need to Know:</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="machine-learning.html"><a href="machine-learning.html#neural-networks-key-concepts-for-data-science-interviews"><i class="fa fa-check"></i><b>4.8</b> Neural Networks: Key Concepts for Data Science Interviews</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="machine-learning.html"><a href="machine-learning.html#basic-structure"><i class="fa fa-check"></i><b>4.8.1</b> Basic Structure:</a></li>
<li class="chapter" data-level="4.8.2" data-path="machine-learning.html"><a href="machine-learning.html#activation-functions"><i class="fa fa-check"></i><b>4.8.2</b> Activation Functions:</a></li>
<li class="chapter" data-level="4.8.3" data-path="machine-learning.html"><a href="machine-learning.html#forward-and-backpropagation"><i class="fa fa-check"></i><b>4.8.3</b> Forward and Backpropagation:</a></li>
<li class="chapter" data-level="4.8.4" data-path="machine-learning.html"><a href="machine-learning.html#loss-functions"><i class="fa fa-check"></i><b>4.8.4</b> Loss Functions:</a></li>
<li class="chapter" data-level="4.8.5" data-path="machine-learning.html"><a href="machine-learning.html#optimization-algorithms"><i class="fa fa-check"></i><b>4.8.5</b> Optimization Algorithms:</a></li>
<li class="chapter" data-level="4.8.6" data-path="machine-learning.html"><a href="machine-learning.html#regularization-techniques"><i class="fa fa-check"></i><b>4.8.6</b> Regularization Techniques:</a></li>
<li class="chapter" data-level="4.8.7" data-path="machine-learning.html"><a href="machine-learning.html#common-architectures"><i class="fa fa-check"></i><b>4.8.7</b> Common Architectures:</a></li>
<li class="chapter" data-level="4.8.8" data-path="machine-learning.html"><a href="machine-learning.html#overfitting-and-underfitting"><i class="fa fa-check"></i><b>4.8.8</b> Overfitting and Underfitting:</a></li>
<li class="chapter" data-level="4.8.9" data-path="machine-learning.html"><a href="machine-learning.html#what-you-need-to-know-2"><i class="fa fa-check"></i><b>4.8.9</b> What You Need to Know:</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="machine-learning.html"><a href="machine-learning.html#naive-bayes"><i class="fa fa-check"></i><b>4.9</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="machine-learning.html"><a href="machine-learning.html#bayesian-classification"><i class="fa fa-check"></i><b>4.9.1</b> Bayesian Classification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="extract-transform-loading.html"><a href="extract-transform-loading.html"><i class="fa fa-check"></i><b>5</b> Extract-Transform-Loading</a>
<ul>
<li class="chapter" data-level="5.1" data-path="extract-transform-loading.html"><a href="extract-transform-loading.html#outlier-detection"><i class="fa fa-check"></i><b>5.1</b> Outlier Detection</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ml-modeling.html"><a href="ml-modeling.html"><i class="fa fa-check"></i><b>6</b> ML Modeling</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ml-modeling.html"><a href="ml-modeling.html#objective"><i class="fa fa-check"></i><b>6.1</b> Objective</a></li>
<li class="chapter" data-level="6.2" data-path="ml-modeling.html"><a href="ml-modeling.html#data-processing"><i class="fa fa-check"></i><b>6.2</b> Data Processing</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ml-modeling.html"><a href="ml-modeling.html#data-collection"><i class="fa fa-check"></i><b>6.2.1</b> Data collection</a></li>
<li class="chapter" data-level="6.2.2" data-path="ml-modeling.html"><a href="ml-modeling.html#data-cleaning"><i class="fa fa-check"></i><b>6.2.2</b> Data Cleaning</a></li>
<li class="chapter" data-level="6.2.3" data-path="ml-modeling.html"><a href="ml-modeling.html#feature-engineering"><i class="fa fa-check"></i><b>6.2.3</b> Feature Engineering</a></li>
<li class="chapter" data-level="6.2.4" data-path="ml-modeling.html"><a href="ml-modeling.html#implementation-and-impact"><i class="fa fa-check"></i><b>6.2.4</b> Implementation and Impact</a></li>
<li class="chapter" data-level="6.2.5" data-path="ml-modeling.html"><a href="ml-modeling.html#lessons-learned-and-future-work"><i class="fa fa-check"></i><b>6.2.5</b> Lessons Learned and Future Work</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ml-modeling.html"><a href="ml-modeling.html#model-selection"><i class="fa fa-check"></i><b>6.3</b> Model Selection</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="ml-modeling.html"><a href="ml-modeling.html#understand-the-problem-type"><i class="fa fa-check"></i><b>6.3.1</b> Understand the Problem Type</a></li>
<li class="chapter" data-level="6.3.2" data-path="ml-modeling.html"><a href="ml-modeling.html#understand-the-data"><i class="fa fa-check"></i><b>6.3.2</b> Understand the Data</a></li>
<li class="chapter" data-level="6.3.3" data-path="ml-modeling.html"><a href="ml-modeling.html#select-models-based-on-interpretability-vs.-performance-trade-off"><i class="fa fa-check"></i><b>6.3.3</b> Select Models Based on Interpretability vs.Â Performance Trade-Off</a></li>
<li class="chapter" data-level="6.3.4" data-path="ml-modeling.html"><a href="ml-modeling.html#evaluate-model-complexity-and-training-time"><i class="fa fa-check"></i><b>6.3.4</b> Evaluate Model Complexity and Training Time</a></li>
<li class="chapter" data-level="6.3.5" data-path="ml-modeling.html"><a href="ml-modeling.html#experiment-and-cross-validation"><i class="fa fa-check"></i><b>6.3.5</b> Experiment and Cross-Validation</a></li>
<li class="chapter" data-level="6.3.6" data-path="ml-modeling.html"><a href="ml-modeling.html#consider-domain-knowledge-and-business-constraints"><i class="fa fa-check"></i><b>6.3.6</b> 6. <strong>Consider Domain Knowledge and Business Constraints</strong></a></li>
<li class="chapter" data-level="6.3.7" data-path="ml-modeling.html"><a href="ml-modeling.html#model-ensembling"><i class="fa fa-check"></i><b>6.3.7</b> 7. <strong>Model Ensembling</strong></a></li>
<li class="chapter" data-level="6.3.8" data-path="ml-modeling.html"><a href="ml-modeling.html#evaluate-and-iterate"><i class="fa fa-check"></i><b>6.3.8</b> 8. <strong>Evaluate and Iterate</strong></a></li>
<li class="chapter" data-level="6.3.9" data-path="ml-modeling.html"><a href="ml-modeling.html#deployment-considerations"><i class="fa fa-check"></i><b>6.3.9</b> 9. <strong>Deployment Considerations</strong></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="ml-modeling.html"><a href="ml-modeling.html#feature-selection"><i class="fa fa-check"></i><b>6.4</b> Feature Selection</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="ml-modeling.html"><a href="ml-modeling.html#recursive-feature-elimination-rfe"><i class="fa fa-check"></i><b>6.4.1</b> Recursive Feature Elimination (RFE)</a></li>
<li class="chapter" data-level="6.4.2" data-path="ml-modeling.html"><a href="ml-modeling.html#lasso-regularization"><i class="fa fa-check"></i><b>6.4.2</b> LASSO regularization</a></li>
<li class="chapter" data-level="6.4.3" data-path="ml-modeling.html"><a href="ml-modeling.html#mutual-information"><i class="fa fa-check"></i><b>6.4.3</b> Mutual Information</a></li>
<li class="chapter" data-level="6.4.4" data-path="ml-modeling.html"><a href="ml-modeling.html#mutual-information-vs-correlation-coefficient"><i class="fa fa-check"></i><b>6.4.4</b> Mutual information vs Correlation Coefficient</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ml-modeling.html"><a href="ml-modeling.html#important-features"><i class="fa fa-check"></i><b>6.5</b> Important Features</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="ml-modeling.html"><a href="ml-modeling.html#feature-importance-in-random-forest"><i class="fa fa-check"></i><b>6.5.1</b> Feature Importance in Random Forest</a></li>
<li class="chapter" data-level="6.5.2" data-path="ml-modeling.html"><a href="ml-modeling.html#using-feature-importance-for-selection"><i class="fa fa-check"></i><b>6.5.2</b> <strong>Using Feature Importance for Selection</strong></a></li>
<li class="chapter" data-level="6.5.3" data-path="ml-modeling.html"><a href="ml-modeling.html#advantages-of-using-random-forest-for-feature-selection"><i class="fa fa-check"></i><b>6.5.3</b> <strong>Advantages of Using Random Forest for Feature Selection</strong></a></li>
<li class="chapter" data-level="6.5.4" data-path="ml-modeling.html"><a href="ml-modeling.html#summary-5"><i class="fa fa-check"></i><b>6.5.4</b> <strong>Summary</strong></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ml-modeling.html"><a href="ml-modeling.html#fine-tuning-hyperparameters"><i class="fa fa-check"></i><b>6.6</b> Fine-tuning hyperparameters</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="ml-modeling.html"><a href="ml-modeling.html#key-hyperparameters-for-tree-based-models"><i class="fa fa-check"></i><b>6.6.1</b> Key Hyperparameters for Tree-Based Models</a></li>
<li class="chapter" data-level="6.6.2" data-path="ml-modeling.html"><a href="ml-modeling.html#fine-tuning-strategy"><i class="fa fa-check"></i><b>6.6.2</b> Fine-Tuning Strategy</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="ml-modeling.html"><a href="ml-modeling.html#cross-validation"><i class="fa fa-check"></i><b>6.7</b> Cross Validation</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="ml-modeling.html"><a href="ml-modeling.html#how-cross-validation-works"><i class="fa fa-check"></i><b>6.7.1</b> How Cross-Validation Works</a></li>
<li class="chapter" data-level="6.7.2" data-path="ml-modeling.html"><a href="ml-modeling.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>6.7.2</b> <strong>K-Fold Cross-Validation</strong></a></li>
<li class="chapter" data-level="6.7.3" data-path="ml-modeling.html"><a href="ml-modeling.html#advantages-of-k-fold-cross-validation"><i class="fa fa-check"></i><b>6.7.3</b> <strong>Advantages of K-Fold Cross-Validation:</strong></a></li>
<li class="chapter" data-level="6.7.4" data-path="ml-modeling.html"><a href="ml-modeling.html#choosing-the-value-of-k"><i class="fa fa-check"></i><b>6.7.4</b> <strong>Choosing the Value of <span class="math inline">\(k\)</span>:</strong></a></li>
<li class="chapter" data-level="6.7.5" data-path="ml-modeling.html"><a href="ml-modeling.html#alternative-methods"><i class="fa fa-check"></i><b>6.7.5</b> <strong>Alternative Methods:</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="model-evaluation.html"><a href="model-evaluation.html"><i class="fa fa-check"></i><b>7</b> Model Evaluation</a>
<ul>
<li class="chapter" data-level="7.1" data-path="model-evaluation.html"><a href="model-evaluation.html#classification-models-evaluation"><i class="fa fa-check"></i><b>7.1</b> Classification Models: Evaluation</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="model-evaluation.html"><a href="model-evaluation.html#thresholding"><i class="fa fa-check"></i><b>7.1.1</b> Thresholding</a></li>
<li class="chapter" data-level="7.1.2" data-path="model-evaluation.html"><a href="model-evaluation.html#confusion-matrix"><i class="fa fa-check"></i><b>7.1.2</b> Confusion Matrix</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="model-evaluation.html"><a href="model-evaluation.html#roc-curve"><i class="fa fa-check"></i><b>7.2</b> ROC Curve</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="model-evaluation.html"><a href="model-evaluation.html#components-of-the-roc-curve"><i class="fa fa-check"></i><b>7.2.1</b> Components of the ROC Curve:</a></li>
<li class="chapter" data-level="7.2.2" data-path="model-evaluation.html"><a href="model-evaluation.html#how-to-read-the-roc-curve"><i class="fa fa-check"></i><b>7.2.2</b> How to Read the ROC Curve:</a></li>
<li class="chapter" data-level="7.2.3" data-path="model-evaluation.html"><a href="model-evaluation.html#area-under-the-roc-curve-auc"><i class="fa fa-check"></i><b>7.2.3</b> Area Under the ROC Curve (AUC):</a></li>
<li class="chapter" data-level="7.2.4" data-path="model-evaluation.html"><a href="model-evaluation.html#applications-of-roc-curve"><i class="fa fa-check"></i><b>7.2.4</b> Applications of ROC Curve:</a></li>
<li class="chapter" data-level="7.2.5" data-path="model-evaluation.html"><a href="model-evaluation.html#using-the-roc-curve-in-real-examples"><i class="fa fa-check"></i><b>7.2.5</b> Using the ROC Curve in Real Examples</a></li>
<li class="chapter" data-level="7.2.6" data-path="model-evaluation.html"><a href="model-evaluation.html#selecting-the-probability-threshold"><i class="fa fa-check"></i><b>7.2.6</b> Selecting the Probability Threshold:</a></li>
<li class="chapter" data-level="7.2.7" data-path="model-evaluation.html"><a href="model-evaluation.html#roc-curve-example"><i class="fa fa-check"></i><b>7.2.7</b> ROC Curve Example:</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="model-evaluation.html"><a href="model-evaluation.html#overfitting-1"><i class="fa fa-check"></i><b>7.3</b> Overfitting</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="model-evaluation.html"><a href="model-evaluation.html#how-do-you-overcome-overfitting"><i class="fa fa-check"></i><b>7.3.1</b> How Do You Overcome Overfitting?</a></li>
<li class="chapter" data-level="7.3.2" data-path="model-evaluation.html"><a href="model-evaluation.html#data-stratification-technique"><i class="fa fa-check"></i><b>7.3.2</b> Data Stratification Technique</a></li>
<li class="chapter" data-level="7.3.3" data-path="model-evaluation.html"><a href="model-evaluation.html#any-other-way-to-simplify-the-model"><i class="fa fa-check"></i><b>7.3.3</b> Any Other Way to Simplify the Model?</a></li>
<li class="chapter" data-level="7.3.4" data-path="model-evaluation.html"><a href="model-evaluation.html#are-you-using-cross-validation-method"><i class="fa fa-check"></i><b>7.3.4</b> 4. Are You Using Cross-Validation Method?</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="model-evaluation.html"><a href="model-evaluation.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>7.4</b> Bias-Variance Tradeoff</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="model-evaluation.html"><a href="model-evaluation.html#key-concepts-in-bias-variance-tradeoff"><i class="fa fa-check"></i><b>7.4.1</b> Key Concepts in Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="7.4.2" data-path="model-evaluation.html"><a href="model-evaluation.html#error-decomposition-and-tradeoff"><i class="fa fa-check"></i><b>7.4.2</b> Error Decomposition and Tradeoff</a></li>
<li class="chapter" data-level="7.4.3" data-path="model-evaluation.html"><a href="model-evaluation.html#managing-the-bias-variance-tradeoff"><i class="fa fa-check"></i><b>7.4.3</b> Managing the Bias-Variance Tradeoff</a></li>
<li class="chapter" data-level="7.4.4" data-path="model-evaluation.html"><a href="model-evaluation.html#conclusion"><i class="fa fa-check"></i><b>7.4.4</b> Conclusion</a></li>
<li class="chapter" data-level="7.4.5" data-path="model-evaluation.html"><a href="model-evaluation.html#lift-chart"><i class="fa fa-check"></i><b>7.4.5</b> Lift Chart</a></li>
<li class="chapter" data-level="7.4.6" data-path="model-evaluation.html"><a href="model-evaluation.html#roc-curve-receiver-operating-characteristic-curve"><i class="fa fa-check"></i><b>7.4.6</b> ROC Curve (Receiver Operating Characteristic Curve)</a></li>
<li class="chapter" data-level="7.4.7" data-path="model-evaluation.html"><a href="model-evaluation.html#summary-6"><i class="fa fa-check"></i><b>7.4.7</b> Summary</a></li>
<li class="chapter" data-level="7.4.8" data-path="model-evaluation.html"><a href="model-evaluation.html#bootstrapping"><i class="fa fa-check"></i><b>7.4.8</b> Bootstrapping</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="interview-questions.html"><a href="interview-questions.html"><i class="fa fa-check"></i><b>8</b> Interview Questions</a>
<ul>
<li class="chapter" data-level="8.0.1" data-path="interview-questions.html"><a href="interview-questions.html#tell-me-how-do-you-train-a-model-and-evaluate-it"><i class="fa fa-check"></i><b>8.0.1</b> tell me how do you train a model and evaluate it</a></li>
<li class="chapter" data-level="8.0.2" data-path="interview-questions.html"><a href="interview-questions.html#tell-me-how-you-can-use-llm-in-marketingheathcare"><i class="fa fa-check"></i><b>8.0.2</b> tell me how you can use LLM in marketing/heathcare</a></li>
<li class="chapter" data-level="8.0.3" data-path="interview-questions.html"><a href="interview-questions.html#objective-function-in-logistic-regression"><i class="fa fa-check"></i><b>8.0.3</b> objective function in logistic regression</a></li>
<li class="chapter" data-level="8.1" data-path="interview-questions.html"><a href="interview-questions.html#do-you-prefer-r-or-python"><i class="fa fa-check"></i><b>8.1</b> Do you prefer R or python?</a></li>
<li class="chapter" data-level="8.2" data-path="interview-questions.html"><a href="interview-questions.html#what-is-your-main-domain"><i class="fa fa-check"></i><b>8.2</b> What is your main domain?</a></li>
<li class="chapter" data-level="8.3" data-path="interview-questions.html"><a href="interview-questions.html#is-this-work-culture-fast-paced-do-you-deliver-value-quickly-or-what"><i class="fa fa-check"></i><b>8.3</b> Is this work culture fast-paced? Do you deliver value quickly or what?</a></li>
<li class="chapter" data-level="8.4" data-path="interview-questions.html"><a href="interview-questions.html#are-you-involved-in-any-efforts-convincing-business-stakeholders-to-adept-models-or-analysis-that-you-do"><i class="fa fa-check"></i><b>8.4</b> Are you involved in any efforts convincing business stakeholders to adept models or analysis that you do</a></li>
<li class="chapter" data-level="8.5" data-path="interview-questions.html"><a href="interview-questions.html#have-you-been-in-a-situation-where-you-feel-like-the-model-is-the-right-way-to-go-but-either-client-or-manager-that-you-need-to-convince"><i class="fa fa-check"></i><b>8.5</b> Have you been in a situation where you feel like the model is the right way to go but either client or manager that you need to convince?</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="interview-prep.html"><a href="interview-prep.html"><i class="fa fa-check"></i><b>9</b> Interview Prep</a>
<ul>
<li class="chapter" data-level="9.1" data-path="interview-prep.html"><a href="interview-prep.html#look-alike-model-walk-thru"><i class="fa fa-check"></i><b>9.1</b> Look alike Model walk thru</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="interview-prep.html"><a href="interview-prep.html#situation"><i class="fa fa-check"></i><b>9.1.1</b> Situation</a></li>
<li class="chapter" data-level="9.1.2" data-path="interview-prep.html"><a href="interview-prep.html#task"><i class="fa fa-check"></i><b>9.1.2</b> Task</a></li>
<li class="chapter" data-level="9.1.3" data-path="interview-prep.html"><a href="interview-prep.html#action"><i class="fa fa-check"></i><b>9.1.3</b> Action</a></li>
<li class="chapter" data-level="9.1.4" data-path="interview-prep.html"><a href="interview-prep.html#result"><i class="fa fa-check"></i><b>9.1.4</b> Result</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://davutemrah.github.io/notebooks/" target="blank">Personal Repo Home</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="machine-learning-fundamentals" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Machine Learning Fundamentals<a href="machine-learning-fundamentals.html#machine-learning-fundamentals" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="definitions" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> definitions<a href="machine-learning-fundamentals.html#definitions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="data-science" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Data Science<a href="machine-learning-fundamentals.html#data-science" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="what-is-data-science" class="section level4 hasAnchor" number="2.1.1.1">
<h4><span class="header-section-number">2.1.1.1</span> What is data science?<a href="machine-learning-fundamentals.html#what-is-data-science" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>At its core, data science is using data to answer questions. This is a pretty broad definition, and thatâs because itâs a pretty broad field!</p>
<p>Data science can involve:</p>
<p>â¢ Statistics, computer science, mathematics</p>
<p>â¢ Data cleaning and formatting</p>
<p>â¢ Data visualization</p>
<p>An Economist Special Report sums up this mÃ©lange of skills well - they state that a data scientist is broadly defined as someone:</p>
<p>âwho combines the skills of software programmer, statistician and storyteller slash artist to extract the nuggets of gold hidden under mountains of dataâ</p>
</div>
<div id="why-do-we-need-data-science" class="section level4 hasAnchor" number="2.1.1.2">
<h4><span class="header-section-number">2.1.1.2</span> Why do we need data science?<a href="machine-learning-fundamentals.html#why-do-we-need-data-science" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>One of the reasons for the rise of data science in recent years is the vast amount of data currently available and being generated. Not only are massive amounts of data being collected about many aspects of the world and our lives, but we simultaneously have the rise of inexpensive computing. This has created the perfect storm in which we have rich data and the tools to analyse it: Rising computer memory capabilities, better processors, more software and now, more data scientists with the skills to put this to use and answer questions using this data!</p>
<p>There is a little anecdote that describes the truly exponential growth of data generation we are experiencing. In the third century BC, the Library of Alexandria was believed to house the sum of human knowledge. Today, there is enough information in the world to give every person alive 320 times as much of it as historians think was stored in Alexandriaâs entire collection.</p>
<p>And that is still growing.</p>
</div>
<div id="what-is-big-data" class="section level4 hasAnchor" number="2.1.1.3">
<h4><span class="header-section-number">2.1.1.3</span> What is big data?<a href="machine-learning-fundamentals.html#what-is-big-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It has been so integral to the rise of data science. There are a few qualities that characterize big data. The first is <code>volume.</code> As the name implies, big data involves large datasets - and these large datasets are becoming more and more routine. For example, say you had a question about online video - well, YouTube has approximately 300 hours of video uploaded every minute! You would definitely have a lot of data available to you to analyse, but you can see how this might be a difficult problem to wrangle all of that data!</p>
<p>And this brings us to the second quality of big data: <code>velocity.</code> Data is being generated and collected faster than ever before. In our YouTube example, new data is coming at you every minute! In a completely different example, say you have a question about shipping times or routes. Well, most transport trucks have real time GPS data available - you could in real time analyse the trucks movementsâ¦ if you have the tools and skills to do so!</p>
<p>The third quality of big data is <code>variety.</code> In the examples Iâve mentioned so far, you have different types of data available to you. In the YouTube example, you could be analysing video or audio, which is a very unstructured data set, or you could have a database of video lengths, views or comments, which is a much more structured dataset to analyse.</p>
</div>
<div id="descriptive-analysis" class="section level4 hasAnchor" number="2.1.1.4">
<h4><span class="header-section-number">2.1.1.4</span> Descriptive analysis<a href="machine-learning-fundamentals.html#descriptive-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The goal of descriptive analysis is to describe or summarize a set of data. Whenever you get a new dataset to examine, this is usually the first kind of analysis you will perform. Descriptive analysis will generate simple summaries about the samples and their measurements. You may be familiar with common descriptive statistics: measures of central tendency (eg: mean, median, mode) or measures of variability (eg: range, standard deviations or variance).
This type of analysis is aimed at summarizing your sample â not for generalizing the results of the analysis to a larger population or trying to make conclusions. Description of data is separated from making interpretations; generalizations and interpretations require additional statistical steps.
Some examples of purely descriptive analysis can be seen in censuses. Here, the government collects a series of measurements on all of the countryâs citizens, which can then be summarized. Here, you are being shown the age distribution in the US, stratified by sex.</p>
</div>
<div id="exploratory-analysis" class="section level4 hasAnchor" number="2.1.1.5">
<h4><span class="header-section-number">2.1.1.5</span> Exploratory analysis<a href="machine-learning-fundamentals.html#exploratory-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The goal of exploratory analysis is to examine or explore the data and find relationships that werenât previously known. Exploratory analyses explore how different measures might be related to each other but do not confirm that relationship as causitive. Youâve probably heard the phrase âCorrelation does not imply causationâ and exploratory analyses lie at the root of this saying. Just because you observe a relationship between two variables during exploratory analysis, it does not mean that one necessarily causes the other.
Because of this, exploratory analyses, while useful for discovering new connections, should not be the final say in answering a question! It can allow you to formulate hypotheses and drive the design of future studies and data collection, but exploratory analysis alone should never be used as the final say on why or how data might be related to each other.</p>
</div>
<div id="inferential-analysis" class="section level4 hasAnchor" number="2.1.1.6">
<h4><span class="header-section-number">2.1.1.6</span> Inferential analysis<a href="machine-learning-fundamentals.html#inferential-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The goal of inferential analyses is to use a relatively small sample of data to infer or say something about the population at large. Inferential analysis is commonly the goal of statistical modelling, where you have a small amount of information to extrapolate and generalize that information to a larger group.</p>
<p>Inferential analysis typically involves using the data you have to estimate that value in the population and then give a measure of your uncertainty about your estimate. Since you are moving from a small amount of data and trying to generalize to a larger population, your ability to accurately infer information about the larger population depends heavily on your sampling scheme - if the data you collect is not from a representative sample of the population, the generalizations you infer wonât be accurate for the population.</p>
</div>
<div id="predictive-analysis" class="section level4 hasAnchor" number="2.1.1.7">
<h4><span class="header-section-number">2.1.1.7</span> Predictive analysis<a href="machine-learning-fundamentals.html#predictive-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The goal of predictive analysis is to use current data to make predictions about future data. Essentially, you are using current and historical data to find patterns and predict the likelihood of future outcomes.
Like in inferential analysis, your accuracy in predictions is dependent on measuring the right variables. If you arenât measuring the right variables to predict an outcome, your predictions arenât going to be accurate. Additionally, there are many ways to build up prediction models with some being better or worse for specific cases, but in general, having more data and a simple model generally performs well at predicting future outcomes.
All this being said, much like in exploratory analysis, just because one variable may predict another, it does not mean that one causes the other; you are just capitalizing on this observed relationship to predict the second variable.
A common saying is that prediction is hard, especially about the future. There arenât easy ways to gauge how well you are going to predict an event until that event has come to pass; so evaluating different approaches or models is a challenge.</p>
<p>We spend a lot of time trying to predict things - the upcoming weather, the outcomes of sports events, and in the example weâll explore here, the outcomes of elections. Weâve previously mentioned Nate Silver of FiveThirtyEight, where they try and predict the outcomes of U.S. elections (and sports matches, too!). Using historical polling data and trends and current polling, FiveThirtyEight builds models to predict the outcomes in the next US Presidential vote - and has been fairly accurate at doing so! FiveThirtyEightâs models accurately predicted the 2008 and 2012 elections and was widely considered an outlier in the 2016 US elections, as it was one of the few models to suggest Donald Trump at having a chance of winning.</p>
</div>
<div id="causal-analysis" class="section level4 hasAnchor" number="2.1.1.8">
<h4><span class="header-section-number">2.1.1.8</span> Causal analysis<a href="machine-learning-fundamentals.html#causal-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The caveat to a lot of the analyses weâve looked at so far is that we can only see correlations and canât get at the cause of the relationships we observe. Causal analysis fills that gap; the goal of causal analysis is to see what happens to one variable when we manipulate another variable - looking at the cause and effect of a relationship.
Generally, causal analyses are fairly complicated to do with observed data alone; there will always be questions as to whether it is correlation driving your conclusions or that the assumptions underlying your analysis are valid. More often, causal analyses are applied to the results of randomized studies that were designed to identify causation. Causal analysis is often considered the gold standard in data analysis, and is seen frequently in scientific studies where scientists are trying to identify the cause of a phenomenon, but often getting appropriate data for doing a causal analysis is a challenge.
One thing to note about causal analysis is that the data is usually analysed in aggregate and observed relationships are usually average effects; so, while on average giving a certain population a drug may alleviate the symptoms of a disease, this causal relationship may not hold true for every single affected individual.</p>
</div>
<div id="experimental-design" class="section level4 hasAnchor" number="2.1.1.9">
<h4><span class="header-section-number">2.1.1.9</span> Experimental Design<a href="machine-learning-fundamentals.html#experimental-design" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Now that weâve looked at the different types of data science questions, we are going to spend some time looking at experimental design concepts. As a data scientist, you are a scientist and as such, need to have the ability to design proper experiments to best answer your data science questions!
What does experimental design mean?
Experimental design is organizing an experiment so that you have the correct data (and enough of it!) to clearly and effectively answer your data science question. This process involves clearly formulating your question in advance of any data collection, designing the best set-up possible to gather the data to answer your question, identifying problems or sources of error in your design, and only then, collecting the appropriate data.
Why should you care?</p>
</div>
<div id="experiemental-design" class="section level4 hasAnchor" number="2.1.1.10">
<h4><span class="header-section-number">2.1.1.10</span> Experiemental Design:<a href="machine-learning-fundamentals.html#experiemental-design" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><strong>Confounding Variables:</strong></li>
</ol>
<p>Confounding variables are outside factors that influence both the independent and dependent variables in a study, potentially distorting the true relationship between them and leading to incorrect conclusions.</p>
<p><strong>Example:</strong> Age is a confounder in a study investigating the relationship between shoe size and literacy, as it affects both variables. Any observed correlation might actually be due to age.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Methods to Control for Confounders:</strong></li>
</ol>
<p><strong>Measuring Confounders:</strong> Measure the confounding variable (e.g., age) and adjust for it in the analysis to isolate the effect of the independent variable.</p>
<p><strong>Fixing Confounders:</strong> Keep the confounder constant (e.g., selecting participants of the same age) to eliminate its influence.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Use of Control Groups:</strong></li>
</ol>
<p>A <strong>control group</strong> does not receive the experimental treatment but still has the dependent variable measured. This allows for comparison against the treatment group to determine the effect of the treatment itself.</p>
<ol start="4" style="list-style-type: decimal">
<li><strong>Blinding and the Placebo Effect:</strong></li>
</ol>
<p><strong>Blinding</strong> is a technique where participants do not know whether they are in the treatment or control group. This reduces biases, such as the <strong>placebo effect</strong>, where participants might feel better just because they believe they are receiving treatment.</p>
<p>A mock treatment (e.g., a sugar pill) is given to the control group to ensure both groups are equally exposed to the placebo effect.</p>
<ol start="5" style="list-style-type: decimal">
<li><strong>Randomization:</strong></li>
</ol>
<p><strong>Randomization</strong> involves randomly assigning participants to treatment or control groups. This helps balance potential confounders across groups, minimizing bias and reducing systematic errors.</p>
<ol start="6" style="list-style-type: decimal">
<li><strong>Replication:</strong></li>
</ol>
<p><strong>Replication</strong> means repeating an experiment with new subjects to confirm the results. This reduces the impact of chance, outliers, or systematic errors and allows for a more accurate assessment of data variability, strengthening the studyâs validity.</p>
</div>
<div id="beware-p-hacking" class="section level4 hasAnchor" number="2.1.1.11">
<h4><span class="header-section-number">2.1.1.11</span> Beware p-hacking!<a href="machine-learning-fundamentals.html#beware-p-hacking" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>p-Hacking occurs when researchers perform numerous tests on a dataset to find any statistically significant results (p &lt; 0.05), even if those results are merely due to chance. For example, if 20 independent tests are conducted, one might expect at least one to show a significant result purely by chance (5%). In the era of big data, itâs easy to perform many tests and unintentionally or intentionally find patterns that seem significant but are actually random.</p>
</div>
<div id="data-types" class="section level4 hasAnchor" number="2.1.1.12">
<h4><span class="header-section-number">2.1.1.12</span> Data types<a href="machine-learning-fundamentals.html#data-types" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p><code>Continuous variables</code> are anything measured on a quantitative scale that could be any fractional number. An example would be something like weight measured in kg.</p></li>
<li><p><code>Ordinal</code> data have a fixed, small (&lt; 100) number of levels but are ordered. This could be for example survey responses where the choices are: poor, fair, good.</p></li>
<li><p><code>Categorical</code> data are data where there are multiple categories, but they arenât ordered. One example would be sex: male or female. This coding is attractive because it is self-documenting.</p></li>
<li><p><code>Missing</code> data are data that are unobserved and you donât know the mechanism. You should code missing values as NA.</p></li>
<li><p><code>Censored</code> data are data where you know the missingness mechanism on some level. Common examples are a measurement being below a detection limit or a patient being lost to follow-up. They should also be coded as NA when you donât have the data. But you should also add a new column to your tidy data called, âVariableNameCensoredâ which should have values of TRUE if censored and FALSE if not.</p></li>
</ul>
</div>
<div id="data-scientists-in-marketing-science" class="section level4 hasAnchor" number="2.1.1.13">
<h4><span class="header-section-number">2.1.1.13</span> Data scientists in marketing science<a href="machine-learning-fundamentals.html#data-scientists-in-marketing-science" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Data scientists in marketing science play a crucial role in leveraging data-driven insights to optimize marketing strategies and improve decision-making.</p>
<p>Data scientists in marketing science contribute significantly to the development of targeted, efficient, and impactful marketing campaigns by harnessing the power of data and analytics.</p>
<p>Their work helps organizations optimize their marketing spend, enhance customer experiences, and achieve measurable business outcomes.</p>
<p>Here are some key responsibilities and activities that data scientists in marketing science typically engage in:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Data Analysis:</strong></p>
<ul>
<li><p>Conducting extensive data analysis to understand customer behavior, market trends, and other relevant metrics.</p></li>
<li><p>Utilizing statistical methods and machine learning algorithms to extract meaningful patterns and insights from large datasets.</p></li>
</ul></li>
<li><p><strong>Predictive Modeling:</strong></p>
<ul>
<li><p>Developing and deploying predictive models to forecast future trends, customer behavior, and campaign outcomes.</p></li>
<li><p>Using machine learning techniques, such as regression analysis, decision trees, and ensemble methods, to build predictive models.</p></li>
</ul></li>
<li><p><strong>Segmentation and Targeting:</strong></p>
<ul>
<li><p>Creating customer segments based on demographics, behavior, and other relevant factors.</p></li>
<li><p>Optimizing marketing strategies by targeting specific segments with personalized and relevant content.</p></li>
</ul></li>
<li><p><strong>A/B Testing:</strong></p>
<ul>
<li><p>Designing and conducting A/B tests to evaluate the effectiveness of different marketing strategies, campaigns, or variations.</p></li>
<li><p>Analyzing A/B test results to make data-driven recommendations for optimization.</p></li>
</ul></li>
<li><p><strong>Causal Inference:</strong></p>
<ul>
<li><p>Applying advanced causal inference methods to understand the impact of marketing initiatives on customer behavior.</p></li>
<li><p>Assessing the causal relationships between marketing activities and business outcomes.</p></li>
</ul></li>
<li><p><strong>Data Visualization:</strong></p>
<ul>
<li><p>Creating clear and compelling data visualizations to communicate complex insights to non-technical stakeholders.</p></li>
<li><p>Using tools like Tableau, Power BI, or custom scripts to visualize data in a meaningful way.</p></li>
</ul></li>
<li><p><strong>Optimization Strategies:</strong></p>
<ul>
<li><p>Collaborating with marketing teams to develop and optimize marketing strategies based on data insights.</p></li>
<li><p>Recommending adjustments to campaigns, targeting strategies, and budget allocations for better performance.</p></li>
</ul></li>
<li><p><strong>Performance Measurement:</strong></p>
<ul>
<li><p>Developing key performance indicators (KPIs) and metrics to assess the success of marketing campaigns.</p></li>
<li><p>Monitoring and evaluating marketing performance against established benchmarks.</p></li>
</ul></li>
<li><p><strong>Data Management:</strong></p>
<ul>
<li><p>Ensuring the quality and integrity of marketing data by cleaning, preprocessing, and validating datasets.</p></li>
<li><p>Collaborating with data engineers to design and implement data pipelines for efficient data processing.</p></li>
</ul></li>
<li><p><strong>Communication and Collaboration:</strong></p></li>
</ol>
<ul>
<li><p>Effectively communicating findings and insights to non-technical stakeholders, including marketing teams and executives.</p></li>
<li><p>Collaborating with cross-functional teams to align data-driven strategies with overall business objectives.</p></li>
</ul>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="projects.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="machine-learning-fundementals.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/__Foundations/00_00_intro.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Project_Archive.pdf", "Project_Archive.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
